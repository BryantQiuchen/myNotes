# OSI七层模型

> 物理层：底层数据传输，如网线、网卡标准。
>
> 数据链路层：数据的基本格式。如：MAC地址。
>
> 网络层：定义IP编址和路由功能。
>
> 传输层：端到端传输（TCP、UDP）
>
> 会话层：控制应用程序之间的会话能力；如不同软件数据分发给不同的软件
>
> 表示层：数据格式标识，基本压缩加密功能
>
> 应用层：应用软件
>
> （TCP、IP五层模型：物理层、数据链路层、网络层、传输层、应用层）

# 应用层

## HTTP 协议

## HTTP长连接和短链接

## HTTP 和 HTTPS 的区别

## TCP 的 Keepalive 和 HTTP 的 Keep-Alive 是一个东西吗

## 访问一个网页的过程

## DNS解析过程



# 传输层

## TCP 的特点

> TCP 是面向连接的、可靠的、基于字节流的通信协议
>
> **面向连接的：**TCP 需要一对一连接，和 UDP 不同，不支持一对多；
>
> **可靠的：**无论网络链路状况如何，TCP 可以保证一个报文一定能到达接收端；
>
> **字节流：**（无边界 + 有序）UDP 是面向报文的协议，通过 UDP 协议传输时，操作系统不会对消息进行拆分，组装好 UDP 头部后就交给网络层处理，每个 UDP 报文就是一个用户消息的边界；而用户使用 TCP 传输时，消息可能会被操作系统分成多个 TCP 报文，一个完整的用户消息被拆分成多个 TCP 报文进行传输，并且消息是“有序的”，当前一个没有收到时，即使先收到后面的字节，也不能扔给应用层处理，同时重复的报文会自动丢弃。

## TCP 和 UDP 的区别、适用场景

**区别**

> 1. 连接
>
>     TCP：面向连接的，传输前需要建立连接；
>
>     UDP：不需要连接，马上就可以传输数据。
>
> 2. 服务对象
>
>     TCP 仅支持一对一的两点服务；
>
>     UDP 支持一对一、一对多、多对多的交互通信。
>
> 3. 可靠性
>
>     TCP 是可靠交付数据的，保证数据无丢失和按序到达；
>
>     UDP 是尽力而为的，不保证可靠交付数据。
>
> 4. 拥塞控制、流量控制
>
>     TCP 有拥塞控制和流量控制，保证数据传输的安全；
>
>     UDP 没有，即使网络已经十分拥堵了，也不会影响 UDP 的发送速率。
>
> 5. 首部
>
>     TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。
>
>     UDP 首部只有 `8` 个字节，并且是固定不变的，开销较小。
>
> 6. 传输方式
>
>     TCP 是面向字节流的传输协议，消息没有边界，但保证顺序和可靠；
>
>     UDP 是一个包一个包发送，有边界，但可能会丢包和乱序。
>
> 7. 分片
>
>     TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
>
>     UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

**应用场景**

> TCP：
>
> - `FTP` 文件传输；
> - HTTP / HTTPS
>
> UDP：
>
> - 包总量少的通信，如 `DNS` 、`SNMP` 等；
> - 视频、音频等多媒体通信；
> - 广播通信。

## TCP 三次握手的过程

> 开始时，服务器和客户端都处于 `CLOSD` 状态，服务器开启后，主动监听某个端口，此时服务器处于 `LISTEN` 状态；
>
> 客户端希望发起连接请求，随机初始化一个序列号 x，将 TCP 头部中的 SYN 标志位置1，表示 SYN 报文，发送给服务端，表示向服务端发起连接请求，之后客户端处于 `SYN_SENT` 状态；
>
> 服务端收到客户端发来的 SYN 报文后，自己也随机初始化一个序列号 y，同时在 TCP 头部的“确认应答号”字段填入 x+1，TCP 头部中的 SYN 和 ACK 标志位都置1，发送给客户端，之后服务端处于 `SYN_RCVD` 状态；
>
> 客户端收到服务端报文后，还会再向服务器发送最后一个应答报文，该应答报文 TCP 头部的“确认应答号”为 y+1，最后把报文发送给服务端，这次报文可以携带客户端到服务端的数据，之后客户端处于 `ESTABLISHED` 状态；
>
> 服务端收到应答报文后，也进入 `ESTABLISHED` 状态。

## 为什么需要三次握手

> 1. 防止“历史连接”初始化造成混乱。在两次握手的情况下，「被动发起方」没有中间状态给「主动发起方」来阻止历史连接，导致「被动发起方」可能建立一个历史连接，造成资源浪费。（客户端先发送了一个序列号为 100 的 SYN 请求报文，但是阻塞了，又发送了一个新的序列号为 200 的 SYN 请求报文，旧的连接报文先于新的连接报文到达，服务端会恢复一个 SYN + ACK 报文给客户端，客户端收到后根据上下文判断是否是一个历史连接，如果是就发送一个 RST 报文。
> 2. 同步双方序列号。通信双方都需要维护一个「序列号」，标识发送出去的数据包哪些已被对方收到，序列号是保证可靠顺序传输的关键，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样一来一回，才能确保双方的初始序列号能被可靠的同步。
> 3. 避免资源浪费。四次也可以，但三次就可以做到。

## TCP 四次挥手的过程

> - 客户端希望关闭连接，发送一个 FIN 报文，序列号为 x，客户端进入 `FIN_WAIT_1` 状态；
>
> - 服务端收到后，向客户端发送 ACK 应答报文，序列号为 y，ACK 为 x + 1，接着服务端进入 `CLOSED_WAIT` 状态；
>
> - 客户端收到 ACK 后，进入 `FIN_WAIT_2` 状态；
>
> - 服务端处理完数据后，向客户端发送 FIN 报文，之后服务端进入 `LAST_ACK` 状态；
>
> - 客户端收到 FIN 报文后，回一个 ACK 报文，序列号为 y + 1，之后进入 `TIME_WAIT` 状态；
> - 服务端收到客户端发送的 ACK 报文后，进入 `CLOSED` 状态，至此服务端已经完成连接的关闭；
> - 客户端在经过 `2MSL` 时间后，自动进入 `CLOSED` 状态，客户端也完成了连接的关闭。

## 为什么需要四次挥手

> 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。
>
> 服务器收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。
>
> 从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，从而比三次握手导致多了一次。

## 为什么需要 `TIME_WAIT`

> 1. 防止历史连接中的数据，被后面相同的四元组的连接错误接收；
>
>     假如在客户端向服务端发送 FIN 即第一次挥手之前，服务器端发送了一个报文给客户端，但因为网络原因这个报文延迟到达了，那么如果 `TIME_WAIT` 没有或者太短，由于这个报文具有相同的四元组的旧报文，可能会和新TCP连接的新报文起冲突。这个时间足以让两个方向上的数据包都丢弃，使原来连接的数据包在网络中都自然消失，再出现的数据包一定是新建立连接产生的。
>
> 2. 保证「被动关闭连接」的一方，能被正确的关闭。如果客户端最后一次 ACK 报文在网络中丢失了，那么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。假设客户端没有 `TIME_WAIT` 状态，而是在发完最后一次回 ACK 报文就直接进入 `CLOSED` 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。

## 为什么要等待 2MSL

> `MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。
>
> 1. 为了保证客户端发送的最后一个 ACK 报文能够到达服务器端，这个报文可能会丢失，因为使处于 `LAST_ACK` 状态的服务端收不到对已发送的 FIN 报文段的确认，服务端就会重传这个 FIN 报文段, 而客户端就能在 2MSL 时间内收到这个重传的 FIN 报文段，**一来一回需要等待 2 倍的时间**。
> 2. 客户端在发送完最后一个 ACK 报文之后，在经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，这样就可以使下一个连接中不会出现这种已经失效的连接请求报文段。

## 半连接队列(SYN队列)和全连接队列(accept队列)

> 在 TCP 三次握手的时候，Linux 内核会维护两个队列：半连接队列和全连接队列
>
> 当服务器第一次收到客户端的 SYN 之后，就会处于  SYN_RCVD 状态，此时双方还没有完全建立连接。服务器会把这种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列也叫做 SYN 队列，并向客户端响应 SYN + ACK。
>
> 客户端返回  ACK 报文，服务端收到后，从 SYN 队列中移除放到 accept 队列中，等待进程调用 `accept()` 把连接从 accept 队列中取出。

## IP 层会分片，为什么 TCP 层还需要 MSS 呢

> `MTU`：一个网络包的最大长度（IP 头部 + TCP 头部 + TCP 数据）
>
> `MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度
>
> 当 IP 层有一个超过 `MTU` 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 `MTU`。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。当一个 IP 分片丢失，整个 IP 报文都需要重传。但 IP 层本身没有超时重传机制，由传输层的 TCP 负责超时和重传。
>
> 为了能达到最佳的传输效率， TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。
>
> 这样即使重发也是以 MSS 为单位的，不用重传所有分片。

## TCP 粘包怎么解决

> 原因：
>
> 1. 本质原因：TCP 面向字节流，数据没有确切的边界。
> 2. 发送方：TCP 默认使用 Nagle 算法（避免网络中有过多的小包），为了减少网络中报文段的数量。主要有两步，首先上一个分组得到确认后才能发送下一个分组。其次，收集多个小分组然后一起发送。
> 3. 接收方：当接收方收到数据后不会马上交到应用层去处理，因为发送方和接收方各有两个缓冲空间，接收方收到数据后会将数据放到接收方的读缓存中，用户进程从该缓冲区取数据，若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据。
>
> 解决：通过边界划分出有效的用户消息，发送方关闭 Nagle 算法
>
> 1. 固定长度的消息；
> 2. 特殊字符作为边界；（HTTP）
> 3. 自定义消息结构。

## SYN 攻击，如何防范

> **SYN 攻击**：假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入 SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的  ACK 应答，久而久之就会**占满服务端的半连接队列**，使得服务器不能为正常用户服务。
>
> **防范：**
>
> 1. 优化主机系统设置。比如降低 SYN timeout 时间，使得主机尽快释放半连接的占用, 如果短时间内收到了某个 IP 的重复 SYN 请求，我们就认为受到了攻击。我们合理的采用防火墙设置等外部网络也可以进行拦截。

## TCP 流量控制

> TCP不能无脑发，如果接收方处理能差，发送方还无脑发送时候，就会触发重发机制，使得网络拥塞，因此TCP提供了一种机制让发送方根据接收方的实际接受能力控制发送的数据量。
>
> 发送方和接收方都会维护一个窗口，接收方每次收到数据包，可以在发送确定报文的时候，同时告诉发送方自己的缓存区还剩余多少是空闲的，我们也把缓存区的剩余大小称之为接收窗口大小，用变量 win 来表示接收窗口的大小。发送方收到之后，便会调整自己的发送速率，也就是调整自己发送窗口的大小，当发送方收到接收窗口的大小为0时，发送方就会停止发送数据，防止出现大量丢包情况的发生。

## TCP 是如何解决窗口关闭时，潜在的死锁现象呢？

> 当接收方处理好数据，接受窗口 win > 0 时，接收方发个通知报文去通知发送方，告诉他可以继续发送数据了。当发送方收到窗口大于 0 的报文时，就继续发送数据。
>
> TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**如果持续计时器超时，就回发送窗口探测报文，对方确认这个探测报文时，给出自己现在的接受窗口大小。

## 糊涂窗口综合症

> 如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。
>
> 解决：
>
> - 让接收方不通告小窗口给发送方
>
>     接收方设置策略，当窗口大小小于 `min(MSS, 缓存空间/2)`，就会通告窗口为 0，也就阻止了发送方再发送数据。
>
> - 让发送方避免发送小数据
>
>     Nagle 算法，延迟处理，如果两个条件都不满足，发送方就会一直囤积数据：
>
>     - 条件一：要等到窗口大小 >= `MSS` 或是 数据大小 >= `MSS`；
>     - 条件二：收到之前发送数据的 `ack` 回包。

## TCP 拥塞控制

流量控制是防止发送的报文无脑发送填满接收方的缓存，这其中发送方和接收方不知道网络环境是如何变化的，因此当网络出现拥塞的时候，可能会导致包的传输时延增加，丢包等问题，由于重传机制，会进入恶性循环。

> 拥塞控制最直接的目的就是避免发送方的数据填满整个网络

## TCP 协议保证可靠传输的手段

> - 三次握手，建立可信的传输信道
>
> - 校验和，接收端可以检测出来数据是否异常。
>
> - 流量控制
>
> - 拥塞控制
>
> - 停止等待 ARQ 协议
>
>     它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复 ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。
>
> - 重传机制（快速重传、超时重传）

# 网络层

## 为什么 IP 地址和 MAC 地址缺一不可

## ICMP 协议（ping的工作原理）

## ARP 协议、RARP 协议

## DHCP 协议

## NAT 协议