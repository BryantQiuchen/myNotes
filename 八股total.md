自我介绍：面试官，您好，我是徐秋晨，目前是电子科技大学研三的一名学生，专业是通信工程。

主要做了两个和C++网络编程的项目：

第一个项目是在学习网络编程和在github中参考其他优秀的开源项目中完成的基于C++11实现的多线程web服务器，解析http请求，并发模型是基于主从reactor模型和I/O多路复用epoll实现的，MainReactor 只有一个，负责响应 client 的连接请求，并建立连接，它使用一个NIO Selector。在建立连接后用轮询的方式分配给某个SubReactor，因为涉及到跨线程任务分配，需要加锁，这里的锁由某个特定线程中的loop 创建，只会被该线程和主线程竞争。SubReactor 可以有一个或者多个，每个 subReactor 都会在一个独立线程中运行，并且维护一个独立的 NIO Selector。当主线程把新连接分配给了某个 SubReactor，该线程此时可能正阻塞在多路选择器(epoll)的等待中，使用了 eventfd 进行异步唤醒，线程会从 epoll_wait中醒来，得到活跃事件，进行处理。后端日志主要是由多个缓冲区构成的，参考了muduo 介绍了“双缓冲区”的思想，一个主要的，另一个防止第一个写满了没地方写，写满或者时间到了就和另外两个交换**指针**，然后把满的往文件里写。

第二个项目是通过调研 C++ 中的开源协程库和 Golang 中的协程模型设计的基于 C++11 的轻量级对称协程网络库，协程是轻量级的线程实现，其调度完全由开发者进行控制，协程是在用户态中实现的调度，相比于线程，避免了内核态的上下文切换造成了性能损失，协程的切换需要保存当前的上下文，首先是参考了云风的 coroutine 的协程库，使用了 glibc 中的 uncontext 函数集实现了上下文的协程，封装了协程对象和协程调度器，其中每一个线程对应一个 Processor 实例，协程 Coroutine 实例运行在 Processor 的主循环中，Processor 使用 epoller 和定时器 timer 进行任务调度。而 Scheduler 则并不存在一个循环，它是一个全局单例，当某个线程中调用 `co_go()` 运行一个新协程后，实际会调用该实例的方法，选择一个协程最少的 Processor 接管新的协程，当然，用户也可以指定具体某一个 Processor 来接管新的协程；同时参考了 STL 二级空间配置器的设计，实现了对象池，参考 STL 二级空间配置器的设计，对象池每次创建对象时，会先从**内存池**中取出相应大小的块，内存池与对象大小强相关的，有一个空闲链表，每次分配空间都从空间链表中取，如果空闲链表没有内容，首先会分配 `(分配次数+40)*对象大小` 的空间，然后分成一个个的块，挂到空闲链表上。从内存池取出所需内存块后，会判断对象是否拥有 non-trivial （显式定义默认构造、拷贝构造）构造函数，没有的话直接返回，有的话使用 placement new 构造对象。同时对原生的 socket 进行了协程化改造和是使用 C++11 中 stomic 实现了自旋锁，在测试后相比于上一个主从 reactor 模型 QPS 要提升1.5倍左右。

# 网络编程

## 什么是 I/O

所谓的 I/O 就是输入和输出，也可以理解为读和写，针对不同的对象，I/O 模型可以分为磁盘 I/O 和 网络 I/O 模型。

I/O 操作会涉及到用户空间和内核空间的转换，先来理解以下规则：

- 内存空间分为用户空间和内核空间，也称为用户缓冲区和用户缓冲区；
- 用户的应用程序不能直接操作内核空间，需要将数据从内核空间拷贝到用户空间才能使用；
- 无论是 read 操作，还是 write 操作，都只能在内核空间里执行；
- 磁盘 I/O 和网络 I/O 请求加载到内存的数据都是先放在内核空间的。

所谓的读和写操作：

- **读操作：**操作系统检查内核缓冲区有没有需要的数据，如果内核缓冲区就有需要的数据，就把内核空间的数据 copy 到用户空间，供用户的应用程序使用。如果没有相应的数据，对于磁盘 I/O，直接从磁盘中读取到内核缓冲区（这个过程不需要 CPU 参与）；对于网络 I/O，应用数据等待客户端发送数据，如果客户端还没有发送数据，对应的应用程序将阻塞，直到客户端发送了数据，应用程序才会被唤醒，从 Socket 协议找中读取客户端发送的数据到内核空间，然后把内核空间的数据 copy 到用户空间，供应用程序使用。
- **写操作：**用户应用程序将用户空间 copy 到内核空间的缓冲区中（如果没有，需要从磁盘 --> 内核缓冲区 --> 用户缓冲区依次读取），这时对用户程序来说写操作已经完成，对于什么时候再写到磁盘中或者通过网络发出去，由操作系统决定。

## I/O 模型

- 阻塞 I/O
- 非阻塞 I/O
- I/O 多路复用（select, poll, epoll）
- 异步 I/O

## I/O 多路复用

### **select/poll**

select 函数将许多个文件描述符集中到一起进行监视，使用 fd_set 数组保存被监视的文件描述符的变化，这个数组是以位存储在内核中的。即该数组所在的索引就是对应文件描述符的id。

select 实现多路复用的方式是，将已连接的 Socket 都放到一个**文件描述符集合**，然后调用 select 函数将文件描述符集合**拷贝**到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过**遍历**文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合**拷贝**回用户态里，然后用户态还需要再通过**遍历**的方法找到可读或可写的 Socket，然后再对其处理。

对于 select 这种方式，需要进行 **2 次「遍历」文件描述符集合**，一次是在内核态里，一个次是在用户态里 ，而且还会发生 **2 次「拷贝」文件描述符集合**，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。

select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 `1024`，只能监听 0~1023 的文件描述符；poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。

两种方式没有本质的区别，**都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合**，这种方式随着并发数上来，性能的损耗会呈指数级增长。

### **epoll**

epoll 的函数：

```cpp
int epoll_create(int size);
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);
```

1. 调用epoll_create建立一个epoll对象(在epoll文件系统中给这个句柄分配资源)；
2. 调用epoll_ctl向epoll对象中添加套接字；
3. 调用epoll_wait收集发生事件的连接。

epoll 高效的原因主要是 epoll_wait 这个函数。由于我们在调用 epoll_create 时，内核除了帮我们在 epoll 文件系统里建了个 file 结点，在内核 cache 里建了个红黑树用于存储以后 epoll_ctl 传来的 socket 外，还会再建立一个双向链表，用于存储准备就绪的事件，当事件状态发生改变的时候，将改变的状态插入到双向链表中(在内核里面)，当内核通过对双向链表的遍历，可以探索是否有状态发生变化，如果有则将双向链表中的节点搬迁到内核外面。相比较于 select 省去了将数组搬迁到内核，以及在内核中遍历数组，和将遍历结果拷贝到用户态。而且 select 使用的是数组的遍历查找状态的改变进而使用位操作函数，epoll 通过红黑树查找，是通过事件注册可以检测出是读事件，写事件，还是异常事件。当有大量连接但是其中只有一少部分处于活跃状态就会影响到性能，epoll可以处理高并发理论上连接没有限制，

注意使用的时候有一个惊群问题，epoll 的工作模式又分为水平触发和边沿触发，默认情况下使用水平触发通俗理解为可以读多次数据，边沿触发理解为只能读一次一次把数据读完，既然是一次读完会不会存在阻塞式读取呢？当然可以选择使用不阻塞读取防止出现阻塞读取而影响后续的任务安排，select 使用数组记录事件，连接之前已经有确切的事件范围。

**水平触发和边缘触发**

- 在LT（水平触发）模式下，只要这个文件描述符还有数据可读，每次 epoll_wait 都会返回它的事件，提醒用户程序去操作。
- ET（边缘触发）模式下，在它检测到有 I/O 事件时，通过 epoll_wait 调用会得到有事件通知的文件描述符，**对于每一个被通知的文件描述符，如可读，则必须将该文件描述符一直读到空**，让 errno 返回 EAGAIN 为止，否则下次的 epoll_wait 不会返回余下的数据，会丢掉事件。如果 ET 模式不是非阻塞的，那这个一直读或一直写势必会在最后一次阻塞。

**水平触发和边缘触发的应用场景**

LT 的编程会比 ET 的编程更简洁的场景，对于可读事件，ET 模式下的编程需要 read 到 EAGAIN 位置,发来的数据量多且并发量大的时候,还可能造成其他事件的饥饿，需要在应用层再额外代码以保证及时响应，而 LT 可直接每个消息事件 read 固定大小以保证每个连接公平(不管是单线程还是多线程模型)，数据量大的且没读完的下次还会继续触发；对于写事件，ET 会实现更简单高效。例子：要 write 1M 的数据，缓冲区只有 2kb，需要用 `epoll_wait()` 可写事件 EPOLLOUT，对于 ET 模式，直接写完后等就可以了，如果是 LT 模式，写完后，还需要再调用一次 `epoll_ctl` 来删去 EPOLLOUT 事件，否则下次调用 `epoll_wait` 还是会继续触发返回可写事件。

如果是并发量比较大，而且每个连接通信的数据量比较大的情况，为了不饥饿掉其他连接，采用 LT 触发模式注册可读事件，通信框架中限制每个连接接受的最大数据为 1M，假设一个连接中总共会有5M，那当可读事件触发时，就只会读取1M，然后把这份数据缓存在应用层，然后处理其他连接后再回来处理接下来的第二个1M，重复上述逻辑，知道5M数据都取完毕，再把这些数据批量抛给业务逻辑；这样保证了每个业务的吞吐量；2.如果对每个用户实时性要求比较高，就每次尽最大努力读完5M数据后再处理其他可读事件

### epoll 是同步还是异步的？

- 从 IO 层面来看，epoll 绝对是同步的；
- 从消息处理层面来看，epoll 是异步的.

select，poll，epoll 本质上都是同步 I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的（可能通过 while 循环来检测内核将数据准备的怎么样了， 而不是属于内核的一种通知用户态机制），仍然需要 read、write 去读写数据。

用户线程定期轮询 epoll 文件描述符上的事件，事件发生后，读取事件对应的 epoll_data，该结构中包含了文件fd和数据地址，由于采用了 mmap，程序可以直接读取数据（epoll_wait 函数）。有人把 epoll 这种方式叫做同步非阻塞（NIO），因为用户线程需要不停地轮询，自己读取数据，看上去好像只有一个线程在做事情。也有人把这种方式叫做异步非阻塞（AIO），因为毕竟是内核线程负责扫描 fd 列表，并填充事件链表的。个人认为真正理想的异步非阻塞，应该是内核线程填充事件链表后，主动通知用户线程，或者调用应用程序事先注册的回调函数来处理数据，如果还需要用户线程不停的轮询来获取事件信息，就不是太完美了，所以也有不少人认为 epoll 是伪 AIO，还是有道理的。

**epoll 事件**

- EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；
- EPOLLOUT：表示对应的文件描述符可以写；
- EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；
- EPOLLERR：表示对应的文件描述符发生错误；
- EPOLLHUP：表示对应的文件描述符被挂断；
- EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。
- EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里

## 两种处理事件方式

如果要让服务器服务多个客户端，那么最直接的方式就是为每一条连接创建线程。其实创建进程也是可以的，原理是一样的，进程和线程的区别在于线程比较轻量级些，线程的创建和线程间切换的成本要小些，为了描述简述，后面都以线程为例。处理完业务逻辑后，随着连接关闭后线程也同样要销毁了，但是这样不停地创建和销毁线程，不仅会带来性能开销，也会造成浪费资源，而且如果要连接几万条连接，创建几万个线程去应对也是不现实的。要这么解决这个问题呢？我们可以使用「资源复用」的方式。也就是不用再为每个连接创建线程，而是创建一个「线程池」，将连接分配给线程，然后一个线程可以处理多个连接的业务。不过，这样又引来一个新的问题，线程怎样才能高效地处理多个连接的业务？

当一个连接对应一个线程时，线程一般采用「read -> 业务处理 -> send」的处理流程，如果当前连接没有数据可读，那么线程会阻塞在 `read` 操作上（ socket 默认情况是阻塞 I/O），不过这种阻塞方式并不影响其他线程。但是引入了线程池，那么一个线程要处理多个连接的业务，线程在处理某个连接的 `read` 操作时，如果遇到没有数据可读，就会发生阻塞，那么线程就没办法继续处理其他连接的业务。要解决这一个问题，最简单的方式就是将 socket 改成非阻塞，然后线程不断地轮询调用 `read` 操作来判断是否有数据，这种方式虽然该能够解决阻塞的问题，但是解决的方式比较粗暴，因为轮询是要消耗 CPU 的，而且随着一个 线程处理的连接越多，轮询的效率就会越低。

**Reactor 模式**

**定义：**是一种接收多个输入事件的服务器事件驱动处理模式。服务器端通过 IO 多路复用来处理这些输入事件，并将这些事件同步分派给对应的处理线程。Reactor 模式本质上就是将收到的事件进行分发处理。Reactor 模式中有两个关键的组成：

- 主反应堆 Reactor 在一个单独的线程中运行，负责监听和分发事件，将接收到的事件分为监听 socket 和连接 socket，连接 socket 放入任务队列让线程池线程去抢占式调度。

- Handlers 或 Accepter，处理任务队列中具体的逻辑或者建立连接socket。

三种实现：

1. 单 Reactor 单线程

    一个主反应堆 reactor，一个 accepter 或者 handler 来处理接收的事件。

2. 单 Reactor 多线程

    一个主反应堆 reactor 和一个线程池，线程池用来处理分发的事件

3. 主从 Reactor 多线程

    半同步/半反应堆模型。主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理，主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端。

**Proactor 模式**

在 Reactor 模式中，Reactor 等待某个事件或者可应用或者操作的状态发生（比如文件描述符可读写，或者是 Socket 可读写）。 然后把这个事件传给事先注册的 Handler（事件处理函数或者回调函数），由后者来做实际的读写操作。 其中的读写操作都需要应用程序同步操作，所以 Reactor 是非阻塞同步网络模型。 如果把 I/O 操作改为异步，即交给操作系统来完成就能进一步提升性能，这就是异步网络模型 Proactor。

# WebServer 项目

项目描述：使用 C++11 编写的 Web 服务器，可以解析GET 和 HEAD 请求，处理静态资源，并实现了异步日志。

主要工作：
•    利用epoll  边沿触发的I/O  多路复用技术，线程池技术，Reactor 模式实现了多线程高并发模型；
•    利用有限状态机解析HTTP 请求报文，实现处理静态资源的请求；
•    使用基于小根堆实现的定时器，关闭超时的非活动连接；
•    使用双缓冲区技术实现异步的日志系统，记录服务器运行状态

## 线程池

线程池类设计要点：

- 如何定义线程需要去执行的“任务”（Tasks）：
    - 首先要明确的一点是，“任务”是函数。无论你是使用Linux C的pthread库，还是C++的库，创建一个线程，为了让线程工作，都需要向线程传递一个函数。
    - 然而，这个函数是需要预先声明和定义的。但是在线程池工作的时候，如果我们想要线程执行不同功能的函数，不可能提前知道并声明和定义好。所以，为了让线程执行不同的函数，传递给线程的函数中，会调用其他的函数以实现执行正确的任务；
- 选择合适的容器：对于线程，数组这类容器就能满足要求；而对于工作队列（Task Queue），可以选择队列或者链表。
- 正确的上锁：本质上，线程池类可以简化成**生产者/消费者**模型。线程执行task是在消耗资源，往线程池中添加task是在生产资源。这里的资源指的就是需要执行的函数。生产者/消费者模型中，有好几种上锁的方式：互斥锁+条件变量、信号量等。选择一种你习惯使用的就行。



**主要组成部分是三个：**

1. 任务队列，存储需要分配的任务，用队列实现

2. 工作线程。

    工作线程不停地读取任务队列，读取里面的任务并处理。

    如果队列为空，工作线程将会被阻塞，条件变量

    队列不为空，唤醒线程，工作

3. 管理线程。

    周期性的对任务队列中的任务数量以及处于忙碌状态的工作线程个数进行检测，当任务过多就适当创建一些新线程，当任务过少就销毁一些线程。

## 并发模型

MainReactor 只有一个，负责响应 client 的连接请求，并建立连接，它使用一个 NIO Selector。在建立连接后用Round Robin的方式分配给某个 SubReactor,因为涉及到跨线程任务分配，需要加锁，这里的锁由某个特定线程中的 loop 创建，只会被该线程和主线程竞争。

SubReactor 可以有一个或者多个，每个 subReactor 都会在一个独立线程中运行，并且维护一个独立的 NIO Selector。

当主线程把新连接分配给了某个 SubReactor，该线程此时可能正阻塞在多路选择器(epoll)的等待中，怎么得知新连接的到来呢？这里使用了 eventfd 进行异步唤醒，线程会从 epoll_wait 中醒来，得到活跃事件，进行处理。

## 定时器

每个SubReactor持有一个定时器，用于处理超时请求和长时间不活跃的连接。muduo中介绍了时间轮的实现和用stl里set的实现，这里我的实现直接使用了stl里的priority_queue，底层是小根堆，并采用惰性删除的方式，时间的到来不会唤醒线程，而是每次循环的最后进行检查，如果超时了再删，因为这里对超时的要求并不会很高，如果此时线程忙，那么检查时间队列的间隔也会短，如果不忙，也给了超时请求更长的等待时间。

## 日志

Log的实现了学习了muduo，Log的实现分为前端和后端，前端往后端写，后端往磁盘写。为什么要这样区分前端和后端呢？因为只要涉及到IO，无论是网络IO还是磁盘IO，肯定是慢的，慢就会影响其它操作，必须让它快才行。

这里的Log前端是前面所述的IO线程，负责产生log，后端是Log线程，设计了多个缓冲区，负责收集前端产生的log，集中往磁盘写。这样，Log写到后端是没有障碍的，把慢的动作交给后端去做好了。

后端主要是由多个缓冲区构成的，集满了或者时间到了就向文件写一次。采用了muduo介绍了“双缓冲区”的思想，实际采用4个多的缓冲区(为什么说多呢？为什么4个可能不够用啊，要有备无患)。4个缓冲区分两组，每组的两个一个主要的，另一个防止第一个写满了没地方写，写满或者时间到了就和另外两个交换**指针**，然后把满的往文件里写。

## 核心结构

- Channel类：Channel是Reactor结构中的“事件”，它自始至终都属于一个EventLoop，负责一个文件描述符的IO事件，在Channel类中保存这IO事件的类型以及对应的回调函数，当IO事件发生时，最终会调用到Channel类中的回调函数。因此，程序中所有带有读写时间的对象都会和一个Channel关联，包括loop中的eventfd，listenfd，HttpData等。
- EventLoop：One loop per thread意味着每个线程只能有一个EventLoop对象，EventLoop即是时间循环，每次从poller里拿活跃事件，并给到Channel里分发处理。EventLoop中的loop函数会在最底层(Thread)中被真正调用，开始无限的循环，直到某一轮的检查到退出状态后从底层一层一层的退出。

# 协程网络库

•    基于 glibc  的 uncontext 函数集的上下文切换实现了M:N  调度模型下的线程/协程调度器；
•    参考STL 二级空间配置器设计，实现了内存池与协程对象池；
•    将异步处理流程隐藏在底层框架中，上层用户只需使用同步开发的方式就可以获得异步的高性能;
•    对原生socket 的API  进行了类 hook 处理，作了协程化改造；

## 什么是协程

协程就是**用户态线程**，其调度完全由开发者进行控制，因此实现协程的关键就是需要**实现一个用户态线程的调度器**，协程是在用户态中实现的调度，因此避免了内核态的上下文切换造成了性能损失，突破了线程了在 I/O 上的性能瓶颈。

优点：

- 相比于函数:协程避免了传统的函数调用栈，几乎可以无限地递归
- 相比与线程:协程没有内核态的上下文切换，近乎可以无限并发。协程在用户态进程显式的调度，可以把异步操作转换为同步操作，也意味着不需要加锁,避免了加锁过程中不必要的开销。

协程必须支持**挂起/恢复**，因此对于挂起点状态的保存就显得及其关键，我们知道，线程在切换时，它的中断状态会保存在调用栈中。事实上，协程的中断状态也可以通过开辟相应的调用栈来保存。因此，**按照是否开辟相应的调用栈**，我们可以将协程分为两类：

- 有栈协程（Stackful Coroutine）：每个协程都有自己的调用栈，类似于线程的调用栈；（libco、go协程）
- 无栈协程（Stackless Coroutine）：协程中没有自己的调用栈，挂起点的状态通过状态机或闭包来实现。（C++20 中的 cooroutine）

在调度的过程中，根据携程调度权的目标，可以分为两种：

- 对称协程（Symmetric Coroutine）：任一个协程都是相互独立且平等的，调度权可以在任意协程之间转移。
- 非对称协程（Symmetric Coroutine）：协程让出调度权的目标只能是它的调用者，即协程之间存在调用和被调用的关系。

## 进程、线程、协程的区别

**进程**是操作系统进行资源分配的基本单位，每个进程都有自己的独立内存空间。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。

**线程**又叫做轻量级进程，是进程的一个实体，是处理器任务调度和执行的基本单位位。它是比进程更小的能独立运行的基本单位。线程只拥有一点在运行中必不可少的资源(如程序计数器，一组寄存器和栈)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。

**协程**，又称微线程，是一种用户态的轻量级线程，协程的调度完全由用户控制（也就是在用户态执行）。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到线程的堆区，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和线程切换相比，线程数量越多，协程的性能优势就越明显。不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。此外，一个线程的内存在MB级别，而协程只需要KB级别。

- 一个线程可以有多个协程；
- 大多数业务场景下， 线程进程可以看作是同步机制，协程是异步的；
- 线程是抢占式，而协程是非抢占式的，所以需要用户代码释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力；
- 协程并不是取代线程，而且抽象于线程之上。线程是被分割的CPU资源, 协程是组织好的代码流程, 协程需要线程来承载运行。

## 调度器

netco 会根据计算机的核心数开对应的线程数运行协程，其中每一个线程对应一个 Processor 实例，协程 Coroutine 实例运行在 Processor 的主循环中，Processor 使用 epoller 和定时器 timer 进行任务调度。而 Scheduler 则并不存在一个循环，它是一个全局单例，当某个线程中调用 `co_go()` 运行一个新协程后，实际会调用该实例的方法，选择一个协程最少的 Processor 接管新的协程，当然，用户也可以指定具体某一个 Processor 来接管新的协程。

## context

context 类封装了 ucontext 上下文切换的操作，其他需要使用上下文切换的地方都使用 context 类，目的是将来想使用其他库的上下文切换方法是，只需要实现该类中的方法即可，主要实现了四个方法。

```c++
//函数指针设置当前context的上下文入口
void makeContext(void (*func)(), Processor*, Context*);

//直接用当前程序状态设置当前context的上下文
void makeCurContext();

//将当前上下文保存到oldCtx中，然后切换到当前上下文，若oldCtx为空，则直接运行
void swapToMe(Context* pOldCtx);

//获取当前上下文的ucontext_t指针
inline struct ucontext_t* getUCtx() { return &ctx_; };
```

## Coroutine

协程对象，主要实现协程的几个关键方法：`resume()`，`yield()`，但真正的 `yield` 由 Processor 执行，这里的 `yield` 只是修改当前协程的状态方便在 Processor 中执行。

## Epoller

功能有两个：

- 监视 epoll 中是否有事件发生；
- 向 epoll 中添加、修改、删除监视的 fd。值得注意的是，该类并不存储任何协程对象实体，也不维护任何协程对象实体的生命期，使用的是 LT。

初始 `vector` 长度设置为 16。

`epoll_create1()` 设置 `EPOLL_CLOEXEC`

原因：

子进程以写时复制（Copy-On-Write）方式获得父进程的数据空间、堆和栈副本，这其中也包括文件描述符。刚刚fork 成功时，父子进程中相同的文件描述符指向系统文件表中的同一项（这也意味着他们共享同一文件偏移量）。设置后这样进行 `fork()` 后子进程不能使用父进程中的 fd，父进程可以正常使用，进程替换时会自动关闭文件描述符。

## 对象池

参考 STL 二级空间配置器的设计，对象池主要用于创建 coroutine 实例上，对象池每次创建对象时，会先从**内存池**中取出相应大小的块，内存池与对象大小强相关的，有一个空闲链表，每次分配空间都从空间链表中取，如果空闲链表没有内容，首先会分配 `(分配次数+40)*对象大小` 的空间，然后分成一个个的块，挂到空闲链表上，这里空闲链表节点没有使用额外的空间：效仿的 stl 的二级配置器中的方法，将数据和 `next` 指针放在了一个 `union` 中。从内存池取出所需内存块后，会判断对象是否拥有 non-trivial （显式定义默认构造、拷贝构造、... ）构造函数，没有的话直接返回，有的话使用 placement new 构造对象。

## Timer

定时器主要使用的 Linux 的 `timerfd_create` 创建的时钟 fd 配合一个优先队列（小根堆）实现的，原因是要求效率而没有移除协程的需求。小根堆中存放的是时间和协程对象的 pair：`std::priority_queue<std::pair<Time, Coroutine*>`。

```c++
//获取所有已经超时的需要执行的函数
void getExpiredCoroutines(std::vector<Coroutine*>& expiredCoroutines);
//在time时刻需要恢复协程pCo
void runAt(Time time, Coroutine* pCo);
//经过time毫秒恢复协程pCo
void runAfter(Time time, Coroutine* pCo);
void wakeUp();
//给timefd重新设置时间，time是绝对时间
bool resetTimeOfTimefd(Time time);
```

首先，初始化一个 `timefd_create` 一个 timefd，然后将它放入 epoll 中，如果调用 `runAt` 或 `runAfter` 时，先把新来的任务插入到小根堆中，判断是否是最近的任务，是的话调用 `resetTimeOfTimefd` 来更新时间，如果出现超时，`epoll_wait()` 会跳出阻塞，在 Processor 的主循环中首先处理的就是超时事件，方法就是与当前时间对比并取出小根堆中的协程，直到小根堆中所有任务的时间都比当前大，另外，取出来的协程会放在一个数组中，用于在 Processor 循环中执行。

定时器还有另外一个功能，就是唤醒 `epoll_wait()`，当有新的协程加入时，实际就是通过定时器来唤醒的 processor 主循环，并执行新接受的协程。

## processor

```c++
std::queue<Coroutine*> newCoroutines_[2];
// newCoroutines_为双缓冲队列，一个队列存放新来的协程，另一个给Processor主循环用于执行新来的协程，执行完后就交换队列，每加入一个新的协程就会唤醒一次Processor主循环，以立即执行新来的协程。

std::vector<Coroutine*> actCoroutines_;
// 存放EventEpoller发现的活跃事件的队列，当epoll_wait被激活时，Processor主循环会尝试从Epoller中获取活跃的协程，存放在actCoroutine_队列中，然后依次恢复执行。

std::vector<Coroutine*> timerExpiredCo_;
// 存放超时的协程队列，当epoll_wait被激活时，Processor主循环会首先尝试从Timer中获取活跃的协程，存放在timerExpiredCo队列中，然后依次恢复执行。

std::vector<Coroutine*> removedCo_;
// 存放被移除的协程列表，要移除某一个事件会先放在该列表中，一次循环结束才会真正delete
```

执行顺序：

执行超时的协程(`timerExpiredCo_`) ---> 执行新来的协程(`newCoroutines_`) ---> 执行 epoller 中被激活的协程(`actCoroutines_`) ----> 清理 `removerdCo_` 中的协程。

## Scheduler

调度器，指协程应该运行在哪个 Processor 上，netco 中的该类为全局单例，所执行的调度也相对比较简单，其可以让用户指定协程运行在某个 Processor 上，若用户没有指定，则挑选协程数量最少的 Processor 接管新的协程。

在 libgo 和 Golang 中，scheduler 还有一个 steal 的操作，可以将一个协程从一个 Processor 中偷到另一个 Processor 中，因为其 Processor 的主循环是允许阻塞的，并且协程的运行完全由库决定。而 netco 可以让用户指定某个协程一直运行在某个 Processor 上。

# C++ 基础

## C++ 程序到可执行文件的过程

C++ 和 C 语言相似，一个 C++ 程序从源码到执行文件，有四个过程：预编译，编译，汇编，链接

**编译预处理：**在预编译过程中主要处理源代码中的预处理指令，如：

- 将所有的 #define 删除，并且展开所有的宏定义 

- 处理条件预编译指令和#include指令，将被包含的文件插入到预编译指令的 

- 过滤所有的注释 

- 添加行号和文件名标识 

**编译：**针对预处理后的文件进行词法分析、语法分析、语法分析、符号汇总、汇编代码生成，并针对程序的结构或者特定的 CPU 平台进行优化，把 `.cpp` 文件翻译为 `.s` 的汇编代码。

**汇编：**将汇编代码转变为机器可以执行的指令，将汇编代码 `.s` 翻译成机器指令 `.o` 文件，一个 `.cpp` 文件只会生成一个 `.o` 文件。

**链接：**汇编程序生成的目标文件即 `.o` 文件，单独的 `.o` 文件可能无法执行，因为一个程序可能由多个源文件组成，此时就存在多个 `.o` 文件。文件 `A` 中的函数引用了另一个文件 `B` 中定义的符号或者调用了某个库文件中的函数，这就需要链接处理。

## 动态链接和静态链接有什么区别

静态链接：

在链接的时候就已经把要调用的函数或者过程链接到了生成的可执行文件中，就算你去把静态库删除也不会影响可执行文件的执行。生成的静态链接库，Windows 下以 .lib 为后缀，Linux 下以 .a 为后缀。

动态链接：

在链接到时候没有把调用的函数链接进去，而是在执行过程中，再去找要链接的函数，生成的可执行文件中没有函数代码，只包含函数的重定位信息，所以当你删除动态库时，可执行文件就不能运行。生成的动态链接库，Windows 下以 .dll 为后缀，Linux 下以 .so 为后缀。

静态链接占用内存大，但是运行速度较快，效率高

动态链接占用内存较小，但是运行速度没有静态链接块。

## 深浅拷贝的区别

在未定义显示拷贝构造函数的情况下，系统会调用默认的拷贝函数——即浅拷贝，它能够完成成员的一一复制。当数据成员中没有指针时，浅拷贝是可行的；但当数据成员中有指针时，如果采用简单的浅拷贝，则两类中的两个指针将指向同一个地址，当对象快结束时，会调用两次析构函数，而导致指针悬挂现象，此时必须采用深拷贝。

深拷贝和浅拷贝的区别就在于深拷贝会在堆内存中申请另外的空间来存储数据，解决了指针悬挂的问题。当数据成员中包含指针时，就必须要使用深拷贝。

## 内存对齐

概念：计算机中内存的地址空间是按照 byte 来划分的，从理论上讲对任何类型变量的访问可以从内存中的任意地址开始，但实际情况是：在访问特定类型变量的时候通常在特定的内存地址访问，这就需要对这些数据在内存中存放的位置进行限制，各种类型数据按照一定的规则在空间上排列，而不是顺序的一个接一个的排放，这就是对齐。编译器将程序中的每个数据单元的地址安排在机器字的整数倍的地址指向的内存之中。

为什么需要内存对齐？

主要是由于 CPU 的访问内存的特性决定，CPU 访问内存时并不是以字节为单位来读取内存，而是以机器字长为单位，实际机器字长由 CPU 数据总线宽度决定的。实际 CPU 运行时，每一次控制内存读写信号发生时，CPU 可以从内存中读取数据总线宽度的数据，并将其写入到 CPU 的通用寄存器中。比如 32 位 CPU，机器字长为 4 字节，数据总线宽度为 32 位，如果该 CPU 的地址总线宽度也是为 32 位，则其可以访问的地址空间为 `[0,0xffffffff]`。内存对齐的主要目的是为了减少 CPU 访问内存的次数，加大 CPU 访问内存的吞吐量。假设读取 8 个字节的数据，按照每次读取 4 个字节的速度，则 8 个字节需要 CPU 耗费 2 次读取操作。CPU 始终以字长访问内存，如果不进行内存对齐，很可能增加 CPU 访问内存的次数。

## C++ 三大特性

**封装**

把客观事物抽象为类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏，C++ 中将公共的数据或方法使用 public 修饰，而不希望被访问的数据或方法采用 private 修饰。

**继承**

类的派生指的是从已有类产生新类的过程。原有的类成为基类或父类，产生的新类称为派生类或子类，子类继承基类后，可以创建子类对象来调用基类的函数，变量等。

继承有三种方式：

**多态**

使用同一个接口但效果不同（重载实现编译时多态，虚函数实现运行时多态）

多态有两种形式的多态，一种是静态多态，一种是动态多态。

静态多态。静态多态的设计思想：对于相关的对象类型，直接实现它们各自的定义，不需要共有基类，甚至可以没有任何关系。只需要各个具体类的实现中要求相同的接口声明，静态多态本质上就是模板的具现化。

动态多态。对于相关的对象类型，确定它们之间的一个共同功能集，然后在基类中，把这些共同的功能声明为多个公共的虚函数接口。各个子类重写这些虚函数，以完成具体的功能。具体实现就是 C++ 的虚函数。

如何实现多态：

1. 重载。函数重载和运算符重载，编译期。

2. 虚函数。子类的多态性，运行期。

    在继承关系中，对于父类的方法我们也同样使用。但是正常来说，我们希望方法的行为取决于调用方法的对象，而不是指针或引用指向的对象有关。

3. 模板，类模板，函数模板。编译期

## 虚函数

当⼀个类中包含虚函数时，编译器会为该类⽣成⼀个虚函数表，保存该类中虚函数的地址，同样，派⽣类继承基类，派⽣类中⾃然⼀定有虚函数，所以编译器也会为派⽣类⽣成⾃⼰的虚函数表。当我们定义⼀个派⽣类对象时，编译器检测该类型有虚函数，所以为这个派⽣类对象⽣成⼀个虚函数指针，指向该类型的虚函数表，这个虚函数指针的初始化是在构造函数中完成的。

如果有⼀个基类类型的指针，指向派⽣类，那么当调⽤虚函数时，就会根据所指真正对象的虚函数表指针去寻找虚函数的地址，也就可以调⽤派⽣类的虚函数表中的虚函数以此实现多态。

**虚函数表原理**

C++实现虚函数的方法是：为每个类对象添加一个隐藏成员，隐藏成员保存了一个指针，这个指针叫**虚表指针**（vptr），它指向一个**虚函数表**（virtual function table, vtbl）

**虚函数表**就像一个数组，表中有许多的**槽（slot）**，每个槽中存放的是一个虚函数的地址（可以理解为数组里存放着指向每个虚函数的指针）

同一个类的所有[虚函数](https://www.zhihu.com/search?q=虚函数&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1494631092})地址放到一个指针的数组里，每一个类一个表。另外在每一个对象的结构体中放置一个指向虚表的指针。在调用时，根据对象里的[虚表指针](https://www.zhihu.com/search?q=虚表指针&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1494631092})找到对应的虚表，再根据调用函数确定虚表中的哪一个函数地址。在构造时，构造函数开头隐藏了一句把虚表指针指向本类的对应的虚表地址。由于构造顺序一定是先构造父类再构造子类，因此虚表指针在构造父类的时候被指像父类虚表，在构造子类的时候会再被覆盖成指向子类的虚表。因此即使是父类的指针，在调用时找到的也是子类的虚表，子类的函数。

**每个类使用一个虚函数表，每个类对象用一个虚表指针**

**创建时机**

虚函数表创建时机是在编译期间，编译期间编译器就为每个类确定好了对应的虚函数表里的内容，在程序运行时，编译器会把虚函数表的首地址赋值给虚函数表指针，所以，这个虚函数表指针就有值了。

vptr 跟着对象走，所以对象什么时候创建出来，vptr 就什么时候创建出来，也就是运行的时候。

**编译器如何处理虚函数表**

对于派生类来说：

- 拷贝基类的虚函数表，如果是多继承，就拷贝每个基类的虚函数表
- 查看派生类中是否有重写基类的虚函数，如果有，就替换成已经重写后的虚函数地址
- 查看派生类中是否有新添加的虚函数，如果有，就加入到自身的虚函数表中

### **虚析构函数**

如果类是父类，则必须声明为虚析构函数。基类声明一个虚析构函数，为了确保释放派生对象时，按照正确的顺序调用析构函数。

如果父类的析构函数不是虚函数，则不会触发动态绑定（多态），结果就是只会调用父类的析构函数，而不会调用子类的析构函数，从而**可能**导致子类的内存泄漏（如果子类析构函数中存在 free delete 等释放内存操作时）；

如果父类的析构函数是虚函数，则子类的析构函数一定是虚函数（即使是子类的析构函数不加 virtual），则会在父类指针或引用指向一个子类时，触发动态绑定（多态），析构实例化对象时，若是子类则会执行子类的析构函数，同时，编译器会在子类的析构函数中插入父类的析构函数，最终实现了先调用子类析构函数再调用父类析构函数。

如果析构函数不是虚的，那么编译器只会调用对应指针类型的虚构函数。

```cpp
Employee* pe = new Singer;
delete pe;
```

只会调用 Employee 的析构函数而不会调用 Singer 类的析构函数。如果这个类不是父类也可以定义虚析构函数，只是效率方面问题罢了

### 哪些函数不能为虚函数

#### **构造函数**

虚函数通过虚函数表进行调用，类的每个对象中含有一个指向虚函数表的指针，这一指针在构造过程中被初始化，因此当对象没有被构造之前不能调用虚函数。如果构造函数是虚函数，也就没有办法调用构造函数了；虚函数作用是通过基类的指针或引用调用虚函数时发生动态绑定，但是构造函数是在创建对象时自动执行，不可能通过基类的指针或引用去调用，因此构造函数没有必要被定义为虚函数。

#### **静态成员函数**

静态成员函数不能是虚函数，静态成员函数与类相关联，而不是与类的对象相关联。静态成员函数不含有 this 指针，也就无法得到虚表指针，也就无法通过虚函数表调用虚函数。

原因如下：

1. static 成员不属于任何类对象或类实例，所以即使给此函数加上 virtual 也是没有任何意义的。
2. 静态与非静态成员函数之间有一个主要的区别。那就是静态成员函数没有隐藏的 this 指针。对于虚函数，它的调用恰恰需要 this 指针。在有虚函数的类实例中，this 指针调用 vptr 指针，vptr 找到 vtable(虚函数列表)，通过虚函数列表找到需要调用的虚函数的地址。总体来说虚函数的调用关系是：this 指针->vptr->vtable ->virtual 虚函数。所以说，static 静态函数没有 this 指针，也就无法找到虚函数了

#### 内联函数

因为要在编译的时候展开，而虚函数要求动态绑定。另外就是虚函数的类对象必须包含vptr，但是内联函数是没有地址的，编译的时候直接展开了所以不行。

### 编译器如何处理虚函数表

对于派生类来说，编译器简历虚表的过程有三步：

1. 拷贝基类的虚函数表，如果是多继承，就拷贝每个基类的虚函数表
2. 查看派生类中是否有重写基类的虚函数，如果有，就替换成已经重写后的虚函数地址
3. 查看派生类中是否有新添加的虚函数，如果有，就加入到自身的虚函数表中

## 指针和引用的区别

- 指针是一个变量，存储的是一个地址，引用跟原来的变量实质上是同一个东西，是原变量的别名；
- 指针可以为空，引用不能为 NULL 且在定义时必须初始化；
- 指针在初始化后可以改变指向，而引用在初始化之后不可再改变；
- sizeof 指针得到的是本指针的大小，sizeo f引用得到的是引用所指向变量的大小；
- 当把指针作为参数进行传递时，也是将实参的一个拷贝传递给形参，两者指向的地址相同，但不是同一个变量，在函数中改变这个变量的指向不影响实参，而引用却可以。
- 在 C++ 中，指针和引用经常用于函数的参数传递，然而，指针传递参数和引用传递参数是有本质上的不同的：**指针传递**参数本质上是**值传递**的方式，它所传递的是一个地址值。值传递的特点是被调函数对形式参数的任何操作都是作为局部变量进行，不会影响主调函数的实参变量的值。而在**引用传递**过程中， 被调函数的形参虽然也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址（指针放的是实参变量地址的副本）。

## const 关键字

1. const 修饰变量：限定变量为不可修改。

2. const 修饰指针：指针常量和指向常量的指针

3. const 和函数：有以下几种形式

    `const int& fun(int& a); //修饰返回值
    int& fun(const int& a); //修饰形参
    int& fun(int& a) const{} //const成员函数`

4. const 和类：

    - const 修饰成员变量：在某个对象的声明周期内是常量，但是对于整个类而言是可以改变的。因为类可以创建多个对象，不同的对象其 const 成员变量的值是不同的。切记，不能再类内初始化 const 成员变量，因为类的对象没创建前，编译器并不知道 const 成员变量是什么，因此 const 数据成员只能在初始化列表中初始化。
    - const 修饰成员函数：主要目的是防止成员函数修改成员变量的值，即该成员函数并不能修改成员变量。
    - const 对象：常对象，常对象只能调用常函数。

5. 限定成员函数不可以修改任何数据成员

## static 关键字

static 修饰的普通变量初始化在 main 函数执行前

修饰变量：

- 局部变量

    - 局部变量被定义为局部静态变量；
    - 内存中的位置：静态存储区；
    - 初始化：局部的静态变量只能被初始化一次；
    - 作用域：作用域仍为局部作用域，当定义它的函数或者语句块结束的时候，作用域随之结束。

    static 修饰局部变量时，改变了局部变量存储的位置和生命周期（离开作用域后没有被销毁，但不能访问，直到程序结束），但作用域不改变 。

- 全局变量

    - 在全局变量之前加上关键字 static，全局变量就被定义成为一个全局静态变量。
    - 内存中的位置：静态存储区；
    - 初始化：未经初始化的全局静态变量会自动初始化为0；
    - 作用域：本文件中。

    区别全局变量和静态全局变量：

    全局变量本身就是静态存储方式，静态全局变量当然也是静态存储方式。两者的区别在于非静态全局变量的作用域是整个源程序， 当一个源程序由多个源文件组成时，非静态的全局变量在各个源文件中都是有效的（在其他源文件中使用时加上 extern 关键字重新声明即可）。 而**静态全局变量则限制了其作用域， 即只在定义该变量的源文件内有效， 在同一源程序的其它源文件中不能使用它**。

修饰函数：

修饰普通函数，表明函数的作用范围，仅在定义该函数的文件内才能使用。（和全局变量一样限制了作用域）

修饰类：

- 成员变量

    用 static 修饰类的数据成员实际使其成为类的全局变量，会被类的所有对象共享，**包括派生类的对象**。

    因此，static 成员必须在类外进行初始化，而不能在构造函数内进行初始化。不过也可以用 const 修饰 static 数据成员在类内初始化 。

- 成员函数

    用 static 修饰成员函数，使这个类只存在这一份函数，所有对象共享该函数，不含 this 指针。

    静态成员是可以独立访问的，也就是说，无须创建任何对象实例就可以访问。

    **不可以同时用 const 和 static 修饰成员函数。**

    - C++ 编译器在实现 const 的成员函数的时候为了确保该函数不能修改类的实例的状态，会在函数中添加一个隐式的参数 const this*。但当一个成员为 static 的时候，该函数是没有 this 指针的。也就是说此时 const的用法和 static 是冲突的。两者的语意是矛盾的。**static 的作用是表示该函数只作用在类型的静态变量上，与类的实例没有关系；而 const 的作用是确保函数不能修改类的实例的状态**，与类型的静态变量没有关系。因此不能同时用它们。

## C++ 内存布局/程序分段

也可以叫做进程逻辑地址空间

内存从上到下分别是：

- 栈 stack |高地址|
- 堆 heap
- bss 段（全局/静态存储区）
- data 段（常量存储区）
- 代码段 text |低地址|

**栈**：目前绝大部分 CPU 体系都是基于栈来运行程序，栈中主要存放函数的局部变量、函数参数、返回地址等，栈空间一般由操作系统进行默认分配或者程序指定分配，栈空间在进程生存周期一直都存在，当进程退出时，操作系统才会对栈空间进行回收。

**堆**：动态内存分配的都放在堆上，需要手动进行分配和回收，可能会出现内存泄漏和空闲碎片的情况。堆是从低到高的。

**bss 段**：（Block Started by Symbol）存放程序中未初始化的全局变量的一块内存区域，在程序载入时由内核置为0，存储初始化和未初始化的全局变量和静态变量。

**data 段**：static 变量和所有初始化的全局变量都在 data 段中。

> bss 段和 data 段都是静态内存分配，也就是说在编译的时候自动分配的。
>
> bss 和 data 段也有一种说法合起来叫数据段，有三种类型：
>
> 1. 只读数据段，常量与 const 修饰的全局变量
> 2. 可读可写数据段，存放初始化的全局变量和 static 变量
> 3. bss 段，存放未初始化的全局变量

**text 段**：代码段，text 段在内存中被映射为只读，但 .data 和 .bss 是可写的。由编译器在编译连接时自动计算的，当你在链接定位文件中将该符号放置在代码段后，那么该符号表示的值就是代码段大小，编译连接时，该符号所代表的值会自动代入到源程序中。

## 堆和栈区别，哪个分配快

- 申请方式不同：
    - 堆是由程序员管理，需要手动进行分配和回收
    - 栈由编译器自动分配空间
- 申请大小限制：
    - 堆向高地址扩展，是不连续的内存区域，大小可以灵活调整
    - 栈是高地址向低地址扩展，栈底高地址，空间小
- 内存管理机制：
    - 堆：系统有一个记录空闲内存地址的链表，当系统收到程序申请时，遍历该链表，寻找第一个空间大于申请空间的堆结点，删除空闲结点链表中的该结点，并将该结点空间分配给程序（大多数系统会在这块内存空间首地址记录本次分配的大小，这样 delete 才能正确释放本内存空间，另外系统会将多余的部分重新放入空闲链表中）
    - 栈：只要栈的剩余空间大于所申请空间，系统为程序提供内存，否则报异常提示栈溢出。
- 申请效率：
    - 堆由程序员分配，速度慢，有碎片
    - 栈由系统分配，速度快，不会有碎片

## new / delete 与 malloc / free 

**区别：**

- 前者是 C++ 运算符，后者是 C/C++ 语言标准库函数
- new 自动计算要分配的空间大小，malloc 需要手工计算
- new 是类型安全的，malloc 不是
- new 调用名为 **operator new** 的标准库函数分配足够空间并调用相关对象的构造函数，delete 对指针所指对象运行适当的析构函数；然后通过调用名为 **operator delete** 的标准库函数释放该对象所用内存。后者均没有相关调用
- 后者需要库文件支持，前者不用
- new 是封装了 malloc，直接 free 不会报错，但是这只是释放内存，而不会析构对象

**调用 new 操作符分配对象**

1. 调用 operator new 函数分配一块足够大的，原始的空间；
2. 编译器运行相应的构造函数以构造对象，并传入初值；
3. 构造完对象后，就返回一个指向该对象的指针。

**为什么要 new / delete**

在对非基本数据类型的对象使用的时候，对象创建的时候还需要执行构造函数，销毁的时候要执行析构函数。而 malloc/free 是库函数，是已经编译的代码，所以不能把构造函数和析构函数的功能强加给 malloc/free ，所以 new/delete 是必不可少的。

## new、operator new 和 placement new

### **new/delete 与 operator new/operator delete**

new operator/delete operator 就是 `new` 和 `delete` 操作符，而 `operator new/operator delete` 是函数。

new operator

- 调用operator new分配足够的空间，并调用相关对象的构造函数
- 不可以被重载

operator new

- 只分配所要求的空间，不调用相关对象的构造函数。

    当无法满足所要求分配的空间时，如果有 new_handler，则调用 new_handler，否则如果没要求不抛出异常（以 nothrow 参数表达），则执行bad_alloc 异常，否则返回0。

- 可以被重载

- 重载时，返回类型必须声明为void*

- 重载时，第一个参数类型必须为表达要求分配空间的大小（字节），类型为size_t

- 重载时，可以带其它参数

`operator new` 与 `operator delete` 和C语言中的 `malloc` 与 `free` 对应，只负责分配及释放空间。但使用 `operator new` 分配的空间必须使用 `operator delete` 来释放，而不能使用 `free`，因为它们对内存使用的登记方式不同。反过来亦是一样。你可以重载 `operator new` 和 `operator delete` 以实现对内存管理的不同要求，但你不能重载 new operator 或 delete operator 以改变它们的行为。

### placement new

`placement new` 是重载 `operator new` 的一个标准，全局的版本，不能够被自定义的版本代替。它并不分配内存，只是返回指向已经分配好的某段内存的一个指针，因此不能删除它，但需要调用对象的析构函数。

```c++
void *operator new( size_t, void * p ) throw() { return p; }
```

`placement new` 的执行忽略了 `size_t` 参数，只返还第二个参数，其结果是允许用户把一个对象放到一个特定的地方，达到调用构造函数的效果。和其他普通的 `new` 不同的是，它在括号里多了另外一个参数：

```cpp
Widget *p = new Widget; // ordinary new
pi = new(ptr)int; // placement new
```

括号里的参数 `ptr` 是一个指针，它指向一个内存缓冲器，`placement new` 将在这个缓冲器上分配一个对象。

`placement new` 的返回值是这个被构造对象的地址(比如括号中的传递参数)。`placement new` 主要适用于：在对时间要求非常高的应用程序中，因为这些程序分配的时间是确定的；长时间运行而不被打断的程序；以及执行一个垃圾收集器 (garbage collector)。

## `final` 和 `override`

当在父类中使用了虚函数时候，你可能需要在某个子类中对这个虚函数进行重写，以下方法都可以：

```cpp
class A {
 virtual void foo();
}
class B : public A {
 void foo(); //OK
 virtual void foo(); // OK
 void foo() override; //OK
}
```

使用 `override`关键字指定了子类的这个虚函数是重写的父类的，如果你名字不小心打错了的话，编译器是不会编译通过的。

**final**

当不希望某个类被继承，或不希望某个虚函数被重写，可以在类名和虚函数后添加 final 关键字，添加 final 关键字后被继承或重写，编译器会报错。

## C++ 构造函数

类对象被创建时，编译器为对象分配内存空间，并自动调用构造函数，由构造函数完成成员的初始化工作。

因此构造函数的的作用是初始化对象的成员函数。

- **默认构造函数：**如果没有人为构造函数，则编译器会自动默认生成一个无参构造函数。

- **一般构造函数：**包含各种参数，一个类可以有多个一般构造函数，前提是参数的个数和类型和传入参数的顺序都不相同，根据传入参数调用对应的构造函数。

- **拷贝构造函数：**拷⻉构造函数的函数参数为对象本身的引用，用于根据⼀个已存在的对象复制出⼀个新的该类的对象，⼀般在函数中会将已存在的对象的数据成员的值⼀⼀复制到新创建的对象中。如果没有显示的写拷⻉构造函数，则系统会默认创建⼀个拷⻉构造函数，但当类中有指针成员时，最好不要使⽤编译器提供的默认的拷⻉构造函 数，最好⾃⼰定义并且在函数中执⾏深拷⻉。

- **移动构造函数：**有时候我们会遇到这样一种情况，我们用对象 a 初始化对象 b 后对象 a 我们就不在使用了，但是对象 a 的空间还在呀（在析构之前），既然拷贝构造函数，实际上就是把 a 对象的内容复制一份到 b 中，那么为什么我们不能直接使用 a 的空间呢？这样就避免了新的空间的分配，大大降低了构造的成本。这就是移动构造函数设计的初衷。拷贝构造函数中，对于指针，我们一定要采用深层复制，而移动构造函数中，对于指针，我们采用浅层复制。

    但是指针的浅层复制是非常危险的。浅层复制之所以危险，是因为两个指针共同指向一片内存空间，若第一个指针将其释放，另一个指针的指向就不合法了（pointer dangling）。所以我们只要避免第一个指针释放空间就可以了。避免的方法就是将第一个指针（比如a->value）置为NULL，这样在调用析构函数的时候，由于有判断是否为NULL的语句，所以析构a的时候并不会回收a->value指向的空间（同时也是b->value指向的空间）

- **赋值构造函数：**=运算符的重载，类似拷贝构造函数，将 = 右边的类对象赋值给类对象左边的对象，不属于构造函数，=两边的对象必须都要被创建。

- **类型转换构造函数：**有时候不想要隐式转换，用explict关键字修饰。

## 左值和右值

左值：**可以取地址、位于赋值符号左边**的值，左值是表达式结束（不一定是赋值表达式）后依然存在的对象。

1. 变量名、函数名以及数据成员名
2. 返回左值引用的函数调用
3. 由赋值运算符或复合赋值运算符连接的表达式，如(a=b, a-=b等)
4. 解引用表达式*ptr
5. **前置自增和自减表达式(++a, ++b)**
6. 成员访问（点）运算符的结果
7. 由指针访问成员（ `->` ）运算符的结果
8. 下标运算符的结果(`[]`)
9. 字符串字面值("abc")

右值：可以提供数据值的表达式（不一定可以寻址，例如存储于寄存器中的数据）。如：

1. 字面值(字符串字面值除外)，例如1，'a', true等
2. 返回值为非引用的函数调用或操作符重载，例如：str.substr(1, 2), str1 + str2, or it++
3. 后置自增和自减表达式(a++, a--)
4. 算术表达式（x + y;）
5. 逻辑表达式
6. 比较表达式
7. 取地址表达式
8. lambda表达式`auto f = []{return 5;};`

从本质上理解，右值的创建和销毁由编译器幕后控制，程序员只能确保在本行代码有效的，就是右值(包括立即数)；而用户创建的，通过作用域规则可知其生存期的，就是左值(包括函数返回的局部变量的引用以及 const 对象)。

右值又有纯右值和将亡值的说法。非引用返回的临时变量、运算表达式产生的临时变量、原始字面量和 lambda 表达式等都是纯右值。而将亡值是与右值引用相关的表达式，比如，将要被移动的对象、T&& 函数返回值、std::move 返回值和转换为 T&& 的类型的转换函数的返回值等。

## 左值引用和右值引用

右值引用是 C++11 中新增加的一个很重要的特性，他主是要用来解决 C++98/03 中遇到的两个问题

- 第一个问题就是临时对象非必要的昂贵的拷贝操作
- 第二个问题是在模板函数中如何按照参数的实际类型进行转发。

要拿到一个将亡值，就需要用到右值引用：`T &&`。右值引用的声明让这个临时值的生命周期得以延长、只要变量还活着，那么将亡值将继续存活。C++11 提供了 `std::move` 这个方法将左值参数无条件的转换为右值，有了它我们就能够方便的获得一个右值临时对象。

**移动语义**

当编译器看到 && 的时候会判定为右值引用，对编译器来说这是一个临时变量的标识，对于临时变量来说我们仅仅做一次浅拷贝就行，不需要深拷贝，从而解决了前面提到的临时变量拷贝构造产生的性能损失的问题。这就是所谓的移动语义右值引用的一个重要作用是用来支持移动语义的。那我们知道了移动语义是通过右值来匹配临时值的，那么很自然会想到，普通的左值是否也能借助移动语义来优化性能呢？C++11 为了解决这个问题，提供了 std::move 方法来将左值转换为右值，从而方便应用移动语义。move 是将对象资源的所有权从一个对象转移到另一个对象，只是转移，没有内存的拷贝，这就是所谓的 move 语义。

move 实际上它并不能移动任何东西，它唯一的功能是将一个左值强制转换为一个右值引用。如果是一些基本类型比如 int 和 char[10] 定长数组等类型，使用 move 的话仍然会发生拷贝（因为没有对应的移动构造函数）。所以，move 对于含资源（堆内存或句柄）的对象来说更有意义。

**完美转发**

在函数模板中，完全依照模板的参数的类型（即保持参数的左值、右值特征），将参数传递给函数模板中调用的另外一个函数。C++11 中的 std::forward 正是做这个事情的，他会按照参数的实际类型进行转发。

## C++ 类型转换

1. **static_cast**：用于基本数据类型之间的转换，如：void*和其他类型指针之间的转换、子类对象的指针转换成父类对象指针。

    最好把所有**隐式转换**都用 static_cast 代替

2. **const_cast**：用来移除变量的 const 特性，但是不能用于去除变量的常量性，而是去除指向对象的引用或指针的常量性，因此去除对象必须是指针或者引用。

    - 指向常量的指针被转化成非常量指针，并且仍然指向原来的对象；

    - 常量引用被转换成非常量引用，并且仍然指向原来的对象；

    - 常量对象被转换成非常量对象。

3. **dynamic_cast**：不能用于内置类型转换，主要是继承关系的子类和父类之间的转换，一般是downcasting，向下强制转换。

    子类指针指向父类指针，作用和 static_cast 一样，但将父类指针转化成子类指针，static_cast 可能会失败

    **转换成功会返回引用或者指针，失败返回null**

4. **reinterpret_cast**：将任意类型指针转换为其他类型的指针。

    改变指针或者引用的类型

    - 将指针或者引用转换成一个足够长度的整型

    - 将整型转换成指针或引用类型

## lambda 表达式

**lambda 表达式特点**

lambda 表达式定义了一个匿名函数，并且可以捕获一定范围内的变量。lambda 表达式的语法形式简单归纳如下：

```cpp
[capture](params) opt -> ret {body;};
```

其中 `capture` 是捕获列表，`params` 是参数列表，`opt` 是函数选项，`ret` 是返回值类型，`body` 是函数体。

## 智能指针

**为什么要使用智能指针？**

1. 防止内存泄漏：C++ 在堆上申请内存后，需要手动对内存进行释放。
2. 多线程下对象析构问题，造成这个问题本质的原因是类对象自己销毁(析构)的时候无法对自己加锁，所以要独立出来，采用这个中间层。

**shared_ptr**

共享所有权，也就是说多个指针可以指向一个相同的对象，当最后一个shared_ptr离开作用域的时候才会释放掉内存。

**实现原理：**
在 shared_ptr 内部有一个共享引用计数器来自动管理，计数器实际上就是指向该资源指针的个数，每当复制一个 shared_ptr，引用计数会 + 1。当一个 shared_ptr 离开作用域时，引用计数会 - 1，当引用计数为 0 的时候，则 delete 内存。当计数器为0的时候指针才会彻底释放掉这个资源。

**线程安全问题：**

shared_ptr 可能的线程安全隐患大概有如下几种，一是引用计数的加减操作是否线程安全，二是shared_ptr修改指向时，是否线程安全。

1. shared_ptr 的引用计数是原子操作的，所以引用计数的加减是线程安全的。
2. shared_ptr修改指针指向的时候会不安全。 同一个shared_ptr被多个线程“读”是安全的。同一个shared_ptr被多个线程“写”是不安全的(多个线程操作同一个shared_ptr对象)。

**weak_ptr**

它主要是为了配合 `shared_ptr` 而存在的。就像它的名字一样，它本身是一个弱指针，因为它本身是不能直接调用原生指针的方法的。如果想要使用原生指针的方法，需要将其先转换为一个 `shared_ptr`。

主要为了解决 `shared_ptr` 指针循环引用（a 对象持有 b 对象，b 对象持有 a 对象）造成的内存泄露问题，`weak_ptr` 不会增加引用计数，通过将循环引用中的一方修改为弱引用，可以避免内存泄漏。

**方法**

1. expired() 判断所指向的原生指针是否被释放，如果被释放了返回 true，否则返回 false
2. use_count() 返回原生指针的引用计数
3. lock() 返回 shared_ptr，如果原生指针没有被释放，则返回一个非空的 shared_ptr，否则返回一个空的 shared_ptr
4. reset() 将本身置空

**unique_ptr**

`unique_ptr `的核心特点就如它的名字一样，它拥有对持有对象的唯一所有权。即两个 `unique_ptr` 不能同时指向同一个对象，体现在：

1. `unique_ptr` 不能被复制到另外一个 `unique_ptr`
2. `unique_ptr` 所持有的对象只能通过转移语义将所有权转移到另外一个 `unique_ptr`

## std::function 和 std::bind

C++11 的 `std::function` 和 `std::bind` 作用的对象叫做可调用对象：

std::function是一个可调用对象包装器，是一个类模板，可以容纳除了类成员函数指针之外的所有可调用对象，它可以用统一的方式处理函数、函数对象、函数指针，lambda表达式并允许保存和延迟它们的执行，std::function对C++中各种可调用实体(普通函数、Lambda表达式、函数指针、以及其它函数对象等)的封装，形成一个新的可调用的std::function对象，简化调用。

std::bind可以看作一个通用的函数适配器，它接受一个可调用对象，生成一个新的可调用对象来适应原对象的参数列表。std::bind将可调用对象与其参数一起进行绑定，绑定后的结果可以使用std::function保存。std::bind主要有以下两个作用：

1. 将可调用对象和其参数绑定成一个仿函数；
2. 只绑定部分参数，减少可调用对象传入的参数。

## 原子操作

它表示在多个线程访问同一个全局资源的时候，能够确保所有其他的线程都不在同一时间内访问相同的资源。也就是他确保了在同一时刻只有唯一的线程对这个资源进行访问。这有点类似互斥对象对共享资源的访问的保护，但是原子操作更加接近底层，因而效率更高。

互斥对象的使用，保证了同一时刻只有唯一的一个线程对这个共享进行访问，从执行的结果来看，互斥对象保证了结果的正确性，但是也有非常大的性能损失。

# STL

**STL包含6大部件：容器、迭代器、算法、仿函数、适配器和空间配置器。**

- 容器：容纳一组元素的对象，提供各种数据结构。
- 迭代器：提供一种访问容器中每个元素的方法，从实现的角度来说，迭代器是一种将`operator*`, `operator->`, `operator++`等指针操作赋予 重载的类模板。
- 仿函数：一个行为类似函数的对象，调用它就像调用函数一样，重载了`operator()`的类或者类模板。
- 算法：包括查找算法、排序算法等等。
- 适配器：用来修饰容器等，比如queue和stack，底层借助了deque。
- 空间配置器：负责空间配置和管理，是一个实现了动态空间配置，空间管理，空间释放的类模板。

## 空间配置器

**为什么需要空间配置器**

我们知道动态开辟内存时，要在堆上申请，但若是我们需要频繁的在堆开辟释放内存，则就会**在堆上造成很多外部碎片**，浪费了内存空间；每次都要进行调用 **malloc、free** 函数等操作，使空间就会增加一些附加信息，降低了空间利用率；随着外部碎片增多，内存分配器在找不到合适内存情况下需要合并空闲块，浪费了时间，大大降低了效率。于是就设置了二级空间配置器，**当开辟内存<=128bytes时，即视为开辟小块内存，则调用二级空间配置器。**

**二级空间配置器**

1. 维护16条链表，分别是 0-15 号链表，最小 8 字节，以 8 字节逐渐递增，最大 128 字节，你传入一个字节参数，表示你需要多大的内存，会自动帮你校对到第几号链表（如需要13bytes空间，我们会给它分配16bytes大小），在找到第 n 个链表后查看链表是否为空，如果不为空直接从对应的 free_list 中拔出，将已经拨出的指针向后移动一位。

2. 对应的 free_list 为空，先看其内存池是不是空时，如果内存池不为空:

    （1）先检验它剩余空间是否够20个节点大小（即所需内存大小(提升后) * 20），若足够则直接从内存池中拿出20个节点大小空间，将其中一个分配给用户使用，另外19个当作自由链表中的区块挂在相应的 free_list 下，这样下次再有相同大小的内存需求时，可直接拨出。

    （2）如果不够20个节点大小，则看它是否能满足1个节点大小，如果够的话则直接拿出一个分配给用户，然后从剩余的空间中分配尽可能多的节点挂在相应的 free_list 中。

    （3）如果连一个节点内存都不能满足的话，则将内存池中剩余的空间挂在相应的 free_list 中（找到相应的 free_list），然后再给内存池申请内存。

3. 内存池为空，申请内存此时二级空间配置器会使用 malloc() 从 heap 上申请内存，（一次所申请的内存大小为2 * 所需节点内存大小（提升后）* 20 + 一段额外空间），申请40块，一半拿来用，一半放内存池中。

4. malloc 没有成功 在第三种情况下，如果 malloc() 失败了，说明 heap 上没有足够空间分配给我们了，这时，二级空间配置器会从比所需节点空间大的 free_list 中一一搜索，从比它所需节点空间大的 free_list 中拔除一个节点来使用。如果这也没找到，说明比其大的 free_list 中都没有自由区块了，那就要调用一级适配器了。

释放时调用 deallocate() 函数，若释放的 n>128，则调用一级空间配置器，否则就直接将内存块挂上自由链表的合适位置。

## vector

vector 是动态空间，随着元素的加入它内部机制会自行空充空间以容纳新元素。vector 维护了一个连续的线性空间，普通指针就可以满足要求作为 vector 的迭代器，随机访问迭代器。vector 里面其实有三个迭代器，分别是指向空间头部的 iterator，指向空间尾部的 iterator 和指向可用空间的 iterator。当有新的元素插入时，如果当前容量够就直接插入，如果容量不够则扩容至两倍或1.5倍，如果两倍不足，则扩容至足够大的空间。由于扩充过程不是在原有的空间后面追加，而是重新申请一块新的连续内存，所以所有迭代器都会失效。

### reverse 和 resize 的区别

vector 的 reserve 增加了 vector 的 capacity，但是它的 size 没有改变

resize 改变了 vector 的 capacity 同时也增加了它的 size，原因如下：

1. reserve 是容器预留空间，但在空间内不真正创建元素对象，所以在没有添加新的对象之前，不能引用容器内的元素。加入新的元素时，要调用 push_back()/insert() 函数。
2. resize 是改变容器的大小，且在创建对象，因此，调用这个函数之后，就可以引用容器内的对象了，因此当加入新的元素时，用 operator[] 操作符，或者用迭代器来引用元素对象。此时再**调用 push_back() 函数，是加在这个新的空间后面的。**

### vector 支持越界检查吗

通过 operator[] 获取数组元素，不会检查下标有效性，需要检查的时候使用 at 接口

### push_back 和 emplace_back 区别

**使用 push_back() 函数需要调用拷贝构造函数和转移构造函数，而使用 emplace_back() 插入的元素原地构造，不需要触发拷贝构造和转移构造**，效率更高。

### 如何释放空间

vector 的内存占用空间只增不减，比如你首先分配了10,000个字节，然后 erase 掉后面9,999个，留下一个有效元素，但是内存占用仍为10,000个。

**所有的内存空间是在 vector 析构时候才能被系统回收。**

empty() 用来检测容器是否为空的，clear() 可以清空所有元素。但是即使 clear()，vector 所占用的内存空间依然如故，无法保证内存的回收。vector，可以用 swap() 来帮助你释放内存。

```c++
vector().swap(Vec); //清空Vec的内存；
```

## deque

vector 是单向开口的连续线性空间，deque 是一种双向开口的连续线性空间。双向开口就是说 deque 支持从头尾两端进行元素的插入和删除操作。deque没有容量的概念，因为它是动态以分段连续空间组合而成，随时可以增加一段新的空间并连接起来。由于要维护这种整体连续的假象，并提供随机存取的接口。

## map 和 unordered_map

map 底层数据结构：红黑树，有序，不重复

unordered_map 底层数据结构：hash table，无序

**map 缺点**

- 占用的空间大：红黑树的每一个节点需要保存其父节点位置、孩子节点位置及红/黑性质，因此每一个节点占用空间大。
- 查询平均时间不如unordered_map。

**unordered_map 使用什么方法解决 hash 冲突**

拉链法

开放寻址法

## 迭代器失效

### 删除元素

- 删除元素后，指向被删除元素的迭代器、指针和引用会失效（这应该不会令人惊讶。毕竟这些元素已经被销毁了）；
- 删除 deque 中除首尾位置之外的任何元素都会使迭代器、引用和指针失效；
- 指向 vector 或 string 中删除点之后位置的迭代器、引用和指针都会失效；（deque 和 vector 的删除操作会返回一个指向被删元素之后元素的迭代器）
- 对于list和forward_list，指向容器的迭代器、指针和引用仍有效。
- 对于关联容器：指向被删除元素的迭代器、引用和指针会失效

注：`data.map(iter)` 之后，`iter` 已经失效了，所以 `iter` 无法自增，即 `iter++` 就会出 bug。

解决方案，就是在 `iter` 失效之前，先自增。

```c++
1. datamap.erase(iter++);
2.  auto tmpIter = iter; 
	++iter;
	dataMap.erase(tmpIter);
```

### 插入元素

如果容器是 vector 或 string，且存储空间被重新分配，则指向容器的迭代器、指针和引用都会失效。如果存储空间未重新分配，指向插入位置之前的元素的迭代器、指针和引用仍有效，但指向插入位置之后元素的迭代器、指针和引用将会失效。

对于 deque，插入除首尾位置之外的任何位置都会导致迭代器、指针和引用失效。如果在首尾位置添加元素，迭代器会失效，但指向存在的元素的引用和指针不会失效。

## 容器使用场景

### 顺序容器

- 除非有更好的理由选择其他容器，否则应使用 vector。

- 如果程序要求随机访问，应使用 vector 或 deque。

- 如果要求在容器的中间插入或删除元素，应使用 list 或 forward_list。

- 如果程序需要在头尾插入或删除元素，但不会在中间位置进行插入或删除操作，则使用 deque。

- 如果程序只有在读取输入时才需要在容器中间位置插入元素，随后需要随机访问元素，则

    - 首先，确定是否真的需要在容器中间位置添加元素。当处理输入数据时，通常可以很容易地向 vector 追加数据，然后调用标准库的 sort 函数来重排容器中的元素，从而避免在中间位置添加元素。

    - 如果必须在中间位置插入元素，考虑在输入阶段使用 list，一旦输入完成，将 list 中的内容拷贝到一个 vector 中。

- 如果既需要随机访问，有需要再容器中间位置插入、删除元素，考虑随机的访问操作更多还是插入/删除操作更多。

- 当对象较大，或者构造函数复杂时，list 的性能要优于 vector。因为，在对现有元素进行拷贝时，开销较大。

### 关联容器

- map 是关键字值对的集合：关键字起到索引的作用，值则表示与索引相关联的数据。

- set 支持高效的关键字查询操作——检查一个给定的关键字是否在 set 中。

# 进程和线程

## 进程、线程和协程的区别和联系

|          | 进程                                                         | 线程                                               | 协程                                                         |
| -------- | ------------------------------------------------------------ | -------------------------------------------------- | ------------------------------------------------------------ |
| 定义     | 资源分配和拥有的基本单位                                     | 程序执行的基本单位                                 | 用户态的轻量级线程，线程内部调度的基本单位                   |
| 切换情况 | 进程CPU环境(栈、寄存器、页表和文件句柄等)的保存以及新调度的进程CPU环境的设置 | 保存和设置程序计数器、少量寄存器和栈的内容         | 先将寄存器上下文和栈保存，等切换回来的时候再进行恢复         |
| 切换者   | 操作系统                                                     | 操作系统                                           | 用户                                                         |
| 切换过程 | 用户态->内核态->用户态                                       | 用户态->内核态->用户态                             | 用户态(没有陷入内核)                                         |
| 调用栈   | 内核栈                                                       | 内核栈                                             | 用户栈                                                       |
| 拥有资源 | CPU资源、内存资源、文件资源和句柄等                          | 程序计数器、寄存器、栈和状态字                     | 拥有自己的寄存器上下文和栈                                   |
| 并发性   | 不同进程之间切换实现并发，各自占有CPU实现并行                | 一个进程内部的多个线程并发执行                     | 同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理 |
| 系统开销 | 切换虚拟地址空间，切换内核栈和硬件上下文，CPU高速缓存失效、页表切换，开销很大 | 切换时只需保存和设置少量寄存器内容，因此开销很小   | 直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快 |
| 通信方面 | 进程间通信需要借助操作系统                                   | 线程间可以直接读写进程数据段(如全局变量)来进行通信 | 共享内存、消息队列                                           |

1、进程是资源调度的基本单位，运行一个可执行程序会创建一个或多个进程，进程就是运行起来的可执行程序

2、线程是程序执行的基本单位，是轻量级的进程。每个进程中都有唯一的主线程，且只能有一个，主线程和进程是相互依存的关系，主线程结束进程也会结束。多提一句：协程是用户态的轻量级线程，线程内部调度的基本单位

## 进程和线程的区别、联系

**区别**

- 调度：线程是调度的基本单位（PC，状态码，通用寄存器，线程栈及栈指针），进程是拥有资源的基本单位（打开文件，堆，静态区，代码段等）；
- 进程有自己的独立地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段，这种操作非常昂贵。而线程是共享进程中的数据的，使用相同的地址空间，因此 CPU 切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多。
- 并发性：一个进程内多个线程可以并发（最好和 CPU 核数相等），多个进程可以并发，需要进程间通信；
- 拥有资源： 同⼀进程内的线程共享本进程的资源（共享：堆、全局变量、静态变量等，独享：栈、寄存器、程序计数器），但是进程之间的资源是独⽴的；
- 进程切换：消耗的资源⼤。所以涉及到频繁的切换，使⽤线程要好于进程；
- 系统开销：线程创建销毁只需要处理 PC 值，状态码，通用寄存器值，线程栈及栈指针即可；进程创建和销毁需要重新分配及销毁 task_struct 结构。

**联系**

内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。所以，对于线程和进程，我们可以这么理解：当进程只有一个线程时，可以认为进程就等于线程；当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。

## 进程切换

进程由内核管理和调度，进程的切换只能发生在内核态。

进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。

为了控制进程的执行，内核必须有能力挂起在 CPU 上运行的进程，并恢复以前挂起的某个进程执行，这种过程被称为进程切换。

从一个进程到另一个进程的运行的过程，需要经过以下变化：

- 保存处理机的上下文，包括程序计数器和其他寄存器；
- 更新 PCB 信息；
- 把进程的 PCB 移入相应的队列，如就绪、在某事件阻塞等队列；
- 选择另一个进程执行，更新其 PCB；
- 更新内存管理的数据结构；
- 恢复处理机上下文。

## 上下文切换，操作系统是怎么做的上下文切换？

**上下文切换：**

就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

- 进程上下文切换：

    进程可以在用户空间运行，也可以在内核空间运行。**进程是由内核来管理和调度的，进程的切换只能发生在内核态**。进程的上下文不仅包括虚拟内存，栈，全局变量等用户资源空间，还有内核堆栈，寄存器等内核空间。因此进程在切换的时候，需要把用户态资源和内核态资源保存下来，而加载了下一个进程的内核态后，还需要刷新进程的虚拟内存和用户栈。

    进程上下文切换的场景：

    1. 时间片轮转技术下，该进程分配到的时间片耗尽，就会被系统挂起，切换到其他进程
    2. 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。
    3. 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。
    4. 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行
    5. 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。

- 线程上下文切换：

    - 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。
    - 前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。

- 中断上下文切换：

    为了快速响应硬件的事件,中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。

    **中断上下文切换并不涉及到进程的用户态**。即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。只需要关注内核资源就行，CPU寄存器，内核堆栈，硬件中断参数啥的。

## 进程间通信方式

每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，内核是可以共享的。在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为**进程间通信（IPC，InterProcess Communication）**

- 管道：

    是一种半双工的通信方式，数据只能单向流通，实现双向收发，需要建立两个管道。

    管道的实质就是在内核中创建一个缓冲区，管道一端的进程进入管道写数据，另一端的进程进入管道读取数据。

    - 无名管道（内存文件）：只能在具有亲缘关系的进程之间使用。进程的亲缘关系通常是指父子进程关系。

        ```cpp
        #include <unistd.h>
        int pipe(int pipefd[2]);
        ```

    - 有名管道（FIFO 文件，借助文件系统）：但是允许在没有亲缘关系的进程之间使用，管道是先进先出的通信方式。

    缺点：管道本质上是通过内核交换数据的，因此通信效率很低，不适合频繁交换数据的情况。匿名管道的周期随着进程的创建而创建，销毁而销毁。

- 消息队列：

    消息队列是保存在内核中的链表，由一个个独立的数据块组成，消息的接收方和发送方要约定具体的消息类型。当进程从消息队列中读取了相关数据块，则内核会将该数据块删除。跟管道相比，消息队列不一定按照先进先出的方式读取，也可以按照消息类型进行兑取。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

    `int msgget(key_t, key, int msgflg);`

    `int msgsend(int msgid, const void *msg_ptr, size_t msg_sz, int msgflg);`

    消息队列的生命周期与内核相关，如果不显示的删除消息队列，则消息队列会一直存在。

    缺点：不能实现实时通信。数据块是有大小限制的。**消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销**，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。

- 共享内存：

    共享内存技术就是要解决用户态和内核态之间频繁发生拷贝过程的。现代操作系统对于内存管理普遍采用的是虚拟内存技术，每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存空间映射到不同的物理内存中。

    共享内存就是在内核中映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的IPC方式，它是针对其他进程间通信方式运行效率低而专门设计的。共享内存是临界资源，所以需要操作时必须要保证原子性。使用信号量或者互斥锁都可以。

    `int shmget(key_t key, size_t size, int shmflg);` 

- 信号量：

    本质上是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，实现进程、线程的对临界区的同步及互斥访问。

    **信号量表示资源的数量。** **P 操作**会把信号量 -1，-1 之后如果信号量的值 <0，则表示资源已经被占用，进程需要阻塞等待。如果信号量 -1 后 >= 0，表明进程可以正常执行。**V 操作**跟 P 操作正好相反。

- 信号：

    用于通知接收进程某个事件已经发生，比如按下 ctrl + C 就是信号。可以在任何时刻给进程发送信号，信号是进程间通信或操作的一种异步通信机制。

- 套接字：

    适用于不同机器间进程通信，在本地也可作为两个进程通信的方式。

## 线程同步方式

线程间很多资源都是共享的，所以线程间没有像进程间那样有许多数据交换机制。**线程间通信主要目的是为了线程同步。**

- **锁机制**

    - 互斥锁。确保同一时间内只有一个线程能访问共享资源。当资源被占用时其他试图加锁的线程会进入阻塞状态。当锁释放后，哪个线程能上锁取决于内核调度。
    - 读写锁。当以写模式加锁的时候，任何其他线程不论以何种方式加锁都会处以阻塞状态。当以读模式加锁时，读状态不阻塞，但是写状态阻塞。“读模式共享，写模式互斥”
    - 自旋锁。上锁受阻时线程不阻塞而是在循环中轮询查看能否获得该锁，没有线程的切换因而没有切换开销，不过对 CPU 的霸占会导致 CPU 资源的浪费。

- **posix 信号量机制**

    信号量本质上是一个计数器，可以有 PV 操作，来控制多个进程或者线程对共享资源的访问。

    信号量 API 有两组，第一组就是 System V IPC 信号量用于进程间通信的，另外一组就是 POSIX 信号量，信号量原理都是一样的

- **条件变量**

    条件变量提供了线程间的通知机制：当某个共享数据到达某个值的时候，唤醒等待这个共享数据的线程。

## 进程调度算法

- 先来先服务（FCFS）

    非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

- 短作业优先

    非抢占式的调度算法，按最短运行时间进行调度。有利于短作业，长作业可能饿死。

- 最短剩余时间优先

    最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

- 时间片轮转

    将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

- 优先级调度

    为每个进程分配一个优先级，按优先级进行调度。

    为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

- 多级反馈队列

    时间片轮转调度算法和优先级调度算法的结合。

    多级表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短；反馈表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列。

## 线程如何实现？

- 内核线程实现

    内核线程（Kernel-Level Thread,KLT）就是直接由操作系统内核支持的线程，内核通过操纵调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。每个内核线程可以视为内核的一个分身，这种操作系统就有能力同时处理多件事情，支持多线程的内核就叫做多线程内核。

    程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口：轻量级进程（Light Weight Process ，LWP），轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。

- 用户线程实现

    从广义上讲，一个线程只要不是内核线程，就可以认为是用户线程（User Thread，UT）。而狭义上的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知线程存在的实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。使用用户线程的优势在于不需要系统内核支援，劣势也在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理。线程的创建、切换和调度都是需要考虑的问题，因此不叫难。

- 用户线程加轻量级进程混合实现

    线程除了依赖内核线程实现和完全由用户程序自己实现之外，还有一种将内核线程与用户线程一起使用的实现方式。在这种混合实现下，既存在用户线程，也存在轻量级进程。

## 线程调度

- 协同式调度

    使用协同式调度的多线程系统，线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另一个线程上。协同式多线程的最大好处是实现简单，不会有线程同步问题。缺点是线程执行时间不可控制，甚至如果一个线程编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在那里。

- 抢占式调度

    使用抢占式调度的多线程系统，每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定。在这种实现线程调度的方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程阻塞的问题，Java使用的线程调度方式就是抢占式调度。

# 死锁

概念：由于操作系统会产生并发，那会产生一个问题，就是多个进程因为争夺资源而互相陷入等待。

产生死锁的**必要条件**

1. 互斥。某个资源只允许一个进程访问，如果已经有进程访问该资源，则其他进程就不能访问，直到该进程访问结束。
2. 占有的同时等待。一个进程占有资源的同时，还有资源未得到，需要其他进程释放该资源。
3. 不可抢占。别的进程已经占有某资源，自己不能去抢。
4. 循环等待。存在一个链条，每个进程都需要下一个进程的资源。

**避免死锁的方法**

我们要尽量避免四个条件同时产生，因此就要破坏。由于互斥条件是必须的，必须要保证的，因此从后面三条下手。

1. 破坏“占有且等待条件”。

    - 所有进程在开始运行之前，一次性申请到所有所需要的资源。
    - 进程用完的资源释放掉，然后再去请求新的资源，提高利用率。

2. 破坏“不可抢占”条件。

    当进程提出在得到一些资源时候不被满足的情况下，必须释放自己已经保存的资源。

3. 破坏“循环等待”。

    实现资源有序分配策略，所有进程申请资源必须按照顺序执行。

`trylock()`

# 内存

## 内存空间的堆和栈的区别是什么？

栈是由操作系统自动分配的，用于存放函数参数值，局部变量。存储在栈中的数据的生命周期随着函数的执行结束而结束。栈的内存生长方向与堆相反，由高到低，按照变量定义的先后顺序入栈。

堆是由用户自己分配的。如果用户不回收，程序结束后由操作系统自动回收。堆的内存地址生长方向与栈相反，由低到高。

**堆上分配内存的过程：**

操作系统有一个记录空闲内存地址的链表，当系统收到程序的开辟内存申请时候，会遍历该链表，寻找第一个空间大于所申请内存空间的节点。接着把该节点从空闲链表中删除，同时将该空间分配出去给程序使用。同时大多数系统会在内存空间中的首地址记录此次分配的大小，这样 delete 才能正确释放内存空间。由于找到的节点所对应的内存大小不一定正好等于申请内存的大小，OS 会自动的将多余的部分放入空闲链表。

## 虚拟内存

**虚拟内存的基本思想是每个程序都拥有自己的地址空间，这些空间被分割成多个块儿。每一块儿被称作一页或者页面。每一个页面有连续的地址范围。这些页面被映射到物理内存，但是并不是一个程序的所有的页面都必须在内存中才能运行**。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻执行映射。当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失部分装入物理内存并重新执行指令。

**虚拟内存** 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如RAM）的使用也更有效率。

## 内存映射(mmap)

**内存映射：**mmap 是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用 read,write 等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。

**mmap 和常规文件操作的区别**

常规文件需要先将文件页从磁盘拷贝到页缓存中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将页缓存中数据页再次拷贝到内存对应的用户空间中。这样，通过了两次数据拷贝过程，才能完成进程对文件内容的获取任务。

而使用 mmap 操作文件中，创建新的虚拟内存区域和建立文件磁盘地址和虚拟内存区域映射这两步，没有任何文件拷贝操作。而之后访问数据时发现内存中并无数据而发起的缺页异常过程，可以通过已经建立好的映射关系，只使用一次数据拷贝，就从磁盘中将数据传入内存的用户空间中，供进程使用。

## 内存映射（mmap）和共享内存，区别？

1. 共享内存可以直接创建，内存映射需要磁盘文件（匿名映射除外）

2. 共享内存效率更高

3. 内存。

    共享内存，所有的进程操作的是同一块共享内存。

    内存映射，每个进程在自己的虚拟地址空间中有一个独立的内存。

4. 数据安全

    进程突然退出时，共享内存还存在，内存映射区消失

    运行进程的电脑死机，宕机时。在共享内存中的数据会消失。内存映射区的数据 ，由于磁盘文件中的数据还在，所以内存映射区的数据还存在。

5. 生命周期

    内存映射区：进程退出，内存映射区销毁

    共享内存：进程退出，共享内存还在，标记删除（所有的关联的进程数为0），或者关机 如果一个进程退出，会自动和共享内存进行取消关联。

# 写时拷贝底层原理

在 Linux 系统中，调用 fork 系统调用创建子进程时，并不会把父进程所有占用的内存页复制一份，而是与父进程共用相同的内存页，而当子进程或者父进程对内存页进行修改时才会进行复制 —— 这就是著名的写时拷贝机制。如果有多个调用者同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。

传统的 fork 系统调用直接把所有资源复制给新创建的进程，这种实现过于简单并且效率低下，如果父进程中有很多数据的话依次复制个子进程，那么 fork 函数肯定是非常慢的。因此使用写时拷贝会快很多。

**原理**

首先要了解一下内存共享机制。不同进程的虚拟内存地址映射到相同的物理内存地址，那么就实现了共享内存的机制。我们可以用用这种思想来实现写时拷贝。fork() 之后，kernel 把父进程中所有的内存页的权限都设为 read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU 硬件检测到内存页是 read-only 的，于是触发页异常中断（page-fault），陷入 kernel 的一个中断例程。中断例程中，kernel 就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份。这样父进程和子进程都有了属于自己独立的页。

子进程可以执行 exec() 来做自己想要的功能。

# 页面置换算法

**缺页中断：**一个进程所有地址空间里的页面不必全部常驻内存，在执行一条指令时，如果发现他要访问的页没有在内存中（即存在位为0），那么停止该指令的执行，并产生一个页不存在的异常，对应的故障处理程序可通过从物理内存加载该页的方法来排除故障，之后，原先引起的异常的指令就可以继续执行，而不再产生异常。

进程运行时，若其访问的页面不在内存而需将其调入，但内存已无空闲空间时，就需要从内存中调出一页程序或数据，送入磁盘的对换区。选择调出页面的算法就称为页面置换算法。

- 最佳页面置换算法（*OPT*）

    最佳页面置换算法基本思路是，置换在「未来」最长时间不访问的页面。所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。

- 先进先出置换算法（*FIFO*）

    选择在内存驻留时间很长的页面进行中置换

- 最近最久未使用的置换算法（*LRU*）

    发生缺页时，选择最长时间没有被访问的页面进行置换，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。

    虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。

- 时钟页面置换算法（*Lock*）

    把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。

    当发生缺页中断时，算法首先检查表针指向的页面：

    - 如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；
    - 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；

- 最不常用置换算法（*LFU*）

    当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。

    要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。

# Linux惊群效应

**定义：**惊群效应（thundering herd）是指多进程（多线程）在同时阻塞等待同一个事件的时候（休眠状态），如果等待的这个事件发生，那么他就会唤醒等待的所有进程（或者线程），但是最终却只能有一个进程（线程）获得这个时间的“控制权”，对该事件进行处理，而其他进程（线程）获取“控制权”失败，只能重新进入休眠状态，这种现象和性能浪费就叫做惊群效应。

**危害：**

1. Linux 内核对用户进程（线程）频繁地做无效的调度、上下文切换等使系统性能大打折扣。上下文切换（context switch）过高会导致 cpu 像个搬运工，频繁地在寄存器和运行队列之间奔波，更多的时间花在了进程（线程）切换，而不是在真正工作的进程（线程）上面。直接的消耗包括 cpu 寄存器要保存和加载（例如程序计数器）、系统调度器的代码需要执行。间接的消耗在于多核 cache 之间的共享数据。
2. 为了确保只有一个进程（线程）得到资源，需要对资源操作进行加锁保护，加大了系统的开销。目前一些常见的服务器软件有的是通过锁机制解决的，比如 Nginx（它的锁机制是默认开启的，可以关闭）；还有些认为惊群对系统性能影响不大，没有去处理，比如 lighttpd

**Linux 解决方案之 Accept**

Linux 2.6 版本之前，监听同一个 socket 的进程会挂在同一个等待队列上，当请求到来时，会唤醒所有等待的进程。Linux 2.6 版本之后，通过引入一个标记位 WQ_FLAG_EXCLUSIVE，解决掉了 Accept 惊群效应。

# 什么是虚假唤醒？

一般来说我们要在等待wait的时候用while循环。因为会产生虚假唤醒。

pthread 的条件变量等待 `pthread_cond_wait` 是使用阻塞的系统调用实现的（比如 Linux 上的 `futex`），这些阻塞的系统调用在进程被信号中断后，通常会中止阻塞、直接返回 EINTR 错误。同样是阻塞系统调用，你从 `read` 拿到 EINTR 错误后可以直接决定重试，因为这通常不影响它本身的语义。而条件变量等待则不能，因为本线程拿到 EINTR 错误和重新调用 `futex` 等待之间，可能别的线程已经通过 `pthread_cond_signal` 或者 `pthread_cond_broadcast`发过通知了。所以，虚假唤醒的一个可能性是条件变量的等待被信号中断。

在多核处理器下，pthread_cond_signal可能会激活多于一个线程（阻塞在条件变量上的线程）。结果是，当一个线程调用pthread_cond_signal()后，因为多个线程都被唤醒了，很可能其中一个唤醒的线程，先一步改变的condition. 此时另一个线程的condition已经不满足，因此需要加Where再次判断。这种效应成为”**虚假唤醒**”(spurious wakeup)。所以我们把判断条件从if改成while，pthread_cond_wait中的while()不仅仅在等待条件变量**前**检查条件变量，实际上在等待条件变量**后**也检查条件变量。

# 几种典型的锁

**读写锁**

- 多个读者可以同时进行读
- 写者必须互斥（只允许一个写者写，也不能读者写者同时进行）
- 写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）

**互斥锁**

一次只能一个线程拥有互斥锁，其他线程只有等待

互斥锁是在抢锁失败的情况下主动放弃CPU进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以互斥锁在加锁操作时涉及上下文的切换。互斥锁实际的效率还是可以让人接受的，加锁的时间大概100ns左右，而实际上互斥锁的一种可能的实现是先自旋一段时间，当自旋的时间超过阀值之后再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）的效果可能不亚于使用自旋锁

**条件变量**

互斥锁一个明显的缺点是他只有两种状态：锁定和非锁定。而条件变量通过允许线程阻塞和等待另一个线程发送信号的方法弥补了互斥锁的不足，他常和互斥锁一起使用，以免出现竞态条件。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。总的来说**互斥锁是线程间互斥的机制，条件变量则是同步机制。**

**自旋锁**

如果进线程无法取得锁，进线程不会立刻放弃CPU时间片，而是一直循环尝试获取锁，直到获取为止。如果别的线程长时期占有锁，那么自旋就是在浪费CPU做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高。

# OSI七层模型

物理层：底层数据传输，如网线、网卡标准。

数据链路层：数据的基本格式。如：MAC地址。

网络层：定义IP编址和路由功能。

传输层：端到端传输（TCP、UDP）

会话层：控制应用程序之间的会话能力；如不同软件数据分发给不同的软件

表示层：数据格式标识，基本压缩加密功能

应用层：应用软件

（TCP、IP五层模型：物理层、数据链路层、网络层、传输层、应用层）

# 应用层

## HTTP 协议

### **状态码**

1xx: 提示信息, 表示目前是协议处理的中间状态, 还需要后续的操作
2xx: 成功, 报文已经收到并被正确处理				 
3xx: 重定向, 资源位置发生变动, 需要客户端重新发送请求
4xx: 客户端错误, 请求报文有误, 服务器无法处理
5xx: 服务器错误, 服务器在处理请求时内部发生了错误

### 字段

Host字段：客户端发送请求时，用来指定服务器的域名
Connection字段：最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。
User-Agent：客户端程序的信息，就是我发送请求的浏览器信息。
Accept：列出了浏览器可以接收的媒体数据类型：
Accept-Language：告知服务器浏览器能够处理的自然语言集（中文、英文等）。zh-CN中文简体。
Accept-Encoding：告知服务器 浏览器能够处理的压缩方式
Cookie：浏览器记录的用户相关信息。
Content-Length字段：服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据长度。
Content-Type字段：用于服务器回应时，告诉客户端，本次数据是什么格式。
Content-Encoding字段：说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式

## HTTP长连接和短链接

本质上是 TCP 的长连接和短链接，HTTP 属于应用层协议，在传输层使用 TCP 协议，在网络层使用 IP 协议。

- HTTP 短连接：

    客户端和服务器之间的 TCP 连接只能为一个 HTTP 请求服务，当服务器处理完客户的一次 HTTP 请求之后就会主动将 TCP 连接关闭。此后如果客户与同一个服务器进行多次 HTTP 请求的话还需要重新建立 TCP 连接。也就是说客户的多次 HTTP 请求不能共用一个 TCP 连接。

- HTTP 长连接：

    client 向 server 发起连接，server 接受 client 连接，双方建立连接。client 与 server 完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。多次 HTTP 请求共用同一个 TCP 连接。

    【关闭一些长时间没有读写事件发生的连接】

    TCP 保活机制（Keepalive）：在一段时间内连接处于非活动状态，那么服务器端将向客户端发送一个报文，如果服务端没有收到回应，则在一定时间间隔内还会继续发送。当发送次数达到阈值（保活次数）后，确认对方主机不可达，断开连接。

## HTTP 和 HTTPS 的区别

- HTTP 使用明文通信，且没有其他的保护措施，不安全。HTTPS 解决了 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输；
- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输；
- HTTPS 协议需要向 CA 申请数字证书，来保证服务器的身份是可信的。

## TCP 的 Keepalive 和 HTTP 的 Keep-Alive 是一个东西吗

HTTP 的 Keep-Alive，是由**应用层（用户态）** 实现的，称为 HTTP 长连接；

TCP 的 Keepalive，是由 **TCP 层（内核态）** 实现的，称为 TCP 保活机制；

- HTTP 的 Keep-Alive：

    HTTP 协议采用的是请求—应答模式，即客户端发起请求，服务端会返回响应。HTTP 的 Keep-Alive 就是实现了这个功能，可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 **HTTP 长连接**。

- TCP 的 Keepalive：

    TCP 的 Keepalive 这东西其实就是 **TCP 的保活机制**，达到保活机制的触发条件，就会发送探测报文。

    - 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
    - 如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。

    TCP 保活机制可以保证双方没有数据交互的情况下，通过探测报文，确定对方的 TCP 连接是否存活。

## GET 和 POST 区别

GET 是从服务器获取指定的资源，安全且幂等的。

POST 向指定的资源提交要被处理的数据，POST 会修改服务器上的资源，不安全，且不幂等。

## 访问一个网页的过程

1. 解析 URL，提取出域名；
2. DNS 查询，将域名映射到具体的 IP 的值；
3. HTTP 是基于 TCP/IP 协议栈的，因为此需要建立 TCP 连接；
4. 浏览器发送 HTTP 请求；
5. 服务器处理请求；
6. 浏览器接受响应；
7. 关闭TCP连接

## DNS 解析过程

DNS 根据域名查询 IP 地址的过程为：浏览器缓存 --> 操作系统缓存(本地 Hosts 文件) --> 路由器缓存-->本地（ISP）域名服务器缓存 --> 根域名服务器 --> 顶级域名服务器 --> 权限域名服务器。

DNS 是应用层协议，事实上他是为其他应用层协议工作的，包括不限于 HTTP 和 SMTP 以及 FTP，用于将用户提供的主机名解析为 IP 地址。

DNS 服务器一般分三种，根 DNS 服务器，顶级 DNS 服务器，二级 DNS 服务器。

如果某个用户正在用浏览器 `mail.baidu.com` 的网址，当你敲下回车键的一瞬间：

1. 检查**浏览器缓存**中是否存在该域名与 IP 地址的映射关系，如果有则解析结束，没有则继续
2. 到**系统本地**查找映射关系，一般在 `hosts` 文件中，如果有则解析结束，否则继续
3. 到**本地域名服务器**去查询，有则结束，否则继续
4. **本地域名服务器**查询**根域名服务器**，该过程并不会返回映射关系，只会告诉你去下级服务器(顶级域名服务器)查询
5. **本地域名服务器**查询**顶级域名服务器**(即 `com` 服务器)，同样不会返回映射关系，只会引导你去二级域名服务器查询
6. **本地域名服务器**查询**二级域名服务器**(即 `baidu.com` 服务器)，引导去三级域名服务器查询
7. **本地域名服务器**查询**三级域名服务器**(即 `mail.baidu.com` 服务器)，此时已经是最后一级了，如果有则返回映射关系，则**本地域名服务器**加入自身的映射表中，方便下次查询或其他用户查找，同时返回给该用户的计算机，没有找到则网页报错
8. 如果还有下级服务器，则依此方法进行查询，直至返回映射关系或报错

# 传输层

## TCP 的特点

TCP 是面向连接的、可靠的、基于字节流的通信协议

**面向连接的：**TCP 需要一对一连接，和 UDP 不同，不支持一对多；

**可靠的：**无论网络链路状况如何，TCP 可以保证一个报文一定能到达接收端；

**字节流：**（无边界 + 有序）UDP 是面向报文的协议，通过 UDP 协议传输时，操作系统不会对消息进行拆分，组装好 UDP 头部后就交给网络层处理，每个 UDP 报文就是一个用户消息的边界；而用户使用 TCP 传输时，消息可能会被操作系统分成多个 TCP 报文，一个完整的用户消息被拆分成多个 TCP 报文进行传输，并且消息是“有序的”，当前一个没有收到时，即使先收到后面的字节，也不能扔给应用层处理，同时重复的报文会自动丢弃。

## TCP 和 UDP 的区别、适用场景

**区别**

1. 连接

    TCP：面向连接的，传输前需要建立连接；

    UDP：不需要连接，马上就可以传输数据。

2. 服务对象

    TCP 仅支持一对一的两点服务；

    UDP 支持一对一、一对多、多对多的交互通信。

3. 可靠性

    TCP 是可靠交付数据的，保证数据无丢失和按序到达；

    UDP 是尽力而为的，不保证可靠交付数据。

4. 拥塞控制、流量控制

    TCP 有拥塞控制和流量控制，保证数据传输的安全；

    UDP 没有，即使网络已经十分拥堵了，也不会影响 UDP 的发送速率。

5. 首部

    TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。

    UDP 首部只有 `8` 个字节，并且是固定不变的，开销较小。

6. 传输方式

    TCP 是面向字节流的传输协议，消息没有边界，但保证顺序和可靠；

    UDP 是一个包一个包发送，有边界，但可能会丢包和乱序。

7. 分片

    TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。

    UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

**应用场景**

TCP：

- `FTP` 文件传输；
- HTTP / HTTPS

UDP：

- 包总量少的通信，如 `DNS` 、`SNMP` 等；
- 视频、音频等多媒体通信；
- 广播通信。

## TCP 三次握手的过程

1. 开始时，服务器和客户端都处于 `CLOSD` 状态，服务器开启后，主动监听某个端口，此时服务器处于 `LISTEN` 状态；

2. 客户端希望发起连接请求，随机初始化一个序列号 x，将 TCP 头部中的 SYN 标志位置1，表示 SYN 报文，发送给服务端，TCP规定，SYN报文段（即SYN=1的报文段）不能携带数据，但**要消耗掉一个序号**。表示向服务端发起连接请求，之后客户端处于 `SYN_SENT` 状态；
3. 服务端收到客户端发来的 SYN 报文后，自己也随机初始化一个序列号 y，同时在 TCP 头部的“确认应答号”字段填入 x+1，TCP 头部中的 SYN 和 ACK 标志位都置1，这次的也不能携带数据，发送给客户端，之后服务端处于 `SYN_RCVD` 状态；
4. 客户端收到服务端报文后，还会再向服务器发送最后一个应答报文，该应答报文 TCP 头部的“确认应答号”为 y+1，最后把报文发送给服务端，这次报文可以携带客户端到服务端的数据，之后客户端处于 `ESTABLISHED` 状态；
5. 服务端收到应答报文后，也进入 `ESTABLISHED` 状态。

## 为什么需要三次握手

1. 防止“历史连接”初始化造成混乱。在两次握手的情况下，「被动发起方」没有中间状态给「主动发起方」来阻止历史连接，导致「被动发起方」可能建立一个历史连接，造成资源浪费。（客户端先发送了一个序列号为 100 的 SYN 请求报文，但是阻塞了，又发送了一个新的序列号为 200 的 SYN 请求报文，旧的连接报文先于新的连接报文到达，服务端会恢复一个 SYN + ACK 报文给客户端，客户端收到后根据上下文判断是否是一个历史连接，如果是就发送一个 RST 报文。
2. 同步双方序列号。通信双方都需要维护一个「序列号」，标识发送出去的数据包哪些已被对方收到，序列号是保证可靠顺序传输的关键，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样一来一回，才能确保双方的初始序列号能被可靠的同步。
3. 避免资源浪费。四次也可以，但三次就可以做到。

## TCP 四次挥手的过程

- 客户端希望关闭连接，发送一个 FIN 报文，序列号为 x，客户端进入 `FIN_WAIT_1` 状态；

- 服务端收到后，向客户端发送 ACK 应答报文，序列号为 y，ACK 为 x + 1，接着服务端进入 `CLOSED_WAIT` 状态；

- 客户端收到 ACK 后，进入 `FIN_WAIT_2` 状态；

- 服务端处理完数据后，向客户端发送 FIN 报文，之后服务端进入 `LAST_ACK` 状态；

- 客户端收到 FIN 报文后，回一个 ACK 报文，序列号为 y + 1，之后进入 `TIME_WAIT` 状态；
- 服务端收到客户端发送的 ACK 报文后，进入 `CLOSED` 状态，至此服务端已经完成连接的关闭；
- 客户端在经过 `2MSL` 时间后，自动进入 `CLOSED` 状态，客户端也完成了连接的关闭。

## 为什么需要四次挥手

关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。

服务器收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，从而比三次握手导致多了一次。

## 为什么需要 `TIME_WAIT`

1. 防止历史连接中的数据，被后面相同的四元组的连接错误接收；

    假如在客户端向服务端发送 FIN 即第一次挥手之前，服务器端发送了一个报文给客户端，但因为网络原因这个报文延迟到达了，那么如果 `TIME_WAIT` 没有或者太短，由于这个报文具有相同的四元组的旧报文，可能会和新TCP连接的新报文起冲突。这个时间足以让两个方向上的数据包都丢弃，使原来连接的数据包在网络中都自然消失，再出现的数据包一定是新建立连接产生的。

2. 保证「被动关闭连接」的一方，能被正确的关闭。如果客户端最后一次 ACK 报文在网络中丢失了，那么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。假设客户端没有 `TIME_WAIT` 状态，而是在发完最后一次回 ACK 报文就直接进入 `CLOSED` 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。

## 为什么要等待 2MSL

`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

1. 为了保证客户端发送的最后一个 ACK 报文能够到达服务器端，这个报文可能会丢失，因为使处于 `LAST_ACK` 状态的服务端收不到对已发送的 FIN 报文段的确认，服务端就会重传这个 FIN 报文段, 而客户端就能在 2MSL 时间内收到这个重传的 FIN 报文段，**一来一回需要等待 2 倍的时间**。
2. 客户端在发送完最后一个 ACK 报文之后，在经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，这样就可以使下一个连接中不会出现这种已经失效的连接请求报文段。

## 半连接队列(SYN队列)和全连接队列(accept队列)

在 TCP 三次握手的时候，Linux 内核会维护两个队列：半连接队列和全连接队列

当服务器第一次收到客户端的 SYN 之后，就会处于  SYN_RCVD 状态，此时双方还没有完全建立连接。服务器会把这种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列也叫做 SYN 队列，并向客户端响应 SYN + ACK。

客户端返回  ACK 报文，服务端收到后，从 SYN 队列中移除放到 accept 队列中，等待进程调用 `accept()` 把连接从 accept 队列中取出。

## IP 层会分片，为什么 TCP 层还需要 MSS 呢

`MTU`：一个网络包的最大长度（IP 头部 + TCP 头部 + TCP 数据）

`MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度

当 IP 层有一个超过 `MTU` 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 `MTU`。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。当一个 IP 分片丢失，整个 IP 报文都需要重传。但 IP 层本身没有超时重传机制，由传输层的 TCP 负责超时和重传。

为了能达到最佳的传输效率， TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。

这样即使重发也是以 MSS 为单位的，不用重传所有分片。

## TCP 粘包怎么解决

出现原因：

1. 本质原因：TCP 面向字节流，数据没有确切的边界。
2. 发送方：TCP 默认使用 Nagle 算法（避免网络中有过多的小包），为了减少网络中报文段的数量。主要有两步，首先上一个分组得到确认后才能发送下一个分组。其次，收集多个小分组然后一起发送。
3. 接收方：当接收方收到数据后不会马上交到应用层去处理，因为发送方和接收方各有两个缓冲空间，接收方收到数据后会将数据放到接收方的读缓存中，用户进程从该缓冲区取数据，若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据。

解决：通过边界划分出有效的用户消息，发送方关闭 Nagle 算法

1. 固定长度的消息；
2. 特殊字符作为边界；（HTTP）
3. 自定义消息结构。

## SYN 攻击，如何防范

**SYN 攻击**：假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入 SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的  ACK 应答，久而久之就会**占满服务端的半连接队列**，使得服务器不能为正常用户服务。

**防范：**

1. 优化主机系统设置。比如降低 SYN timeout 时间，使得主机尽快释放半连接的占用, 如果短时间内收到了某个 IP 的重复 SYN 请求，我们就认为受到了攻击。我们合理的采用防火墙设置等外部网络也可以进行拦截。

## TCP 重传机制

**超时重传：**超时重传指的是发送数据包在一定的时间周期内没有收到相应的 ACK，等待一定的时间，超时之后就认为这个数据包丢失，就会重新发送。这个等待时间被称为 RTO.

**快速重传：**以数据为驱动，连续收到3个相同的 ACK，触发。

**SACK（选择性确认）：**如果开启 SACK，每一个 SACK 段记录的是已经收到的连续的包，这样发送发就知道哪些数据是已经收到了，只重传丢失的。

## TCP 流量控制

TCP不能无脑发，如果接收方处理能差，发送方还无脑发送时候，就会触发重发机制，使得网络拥塞，因此TCP提供了一种机制让发送方根据接收方的实际接受能力控制发送的数据量。

发送方和接收方都会维护一个窗口，接收方每次收到数据包，可以在发送确定报文的时候，同时告诉发送方自己的缓存区还剩余多少是空闲的，我们也把缓存区的剩余大小称之为接收窗口大小，用变量 win 来表示接收窗口的大小。发送方收到之后，便会调整自己的发送速率，也就是调整自己发送窗口的大小，当发送方收到接收窗口的大小为0时，发送方就会停止发送数据，防止出现大量丢包情况的发生。

## TCP 是如何解决窗口关闭时，潜在的死锁现象呢？

当接收方处理好数据，接受窗口 win > 0 时，接收方发个通知报文去通知发送方，告诉他可以继续发送数据了。当发送方收到窗口大于 0 的报文时，就继续发送数据。

TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**如果持续计时器超时，就回发送窗口探测报文，对方确认这个探测报文时，给出自己现在的接受窗口大小。

## 糊涂窗口综合症

如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。

解决：

- 让接收方不通告小窗口给发送方

    接收方设置策略，当窗口大小小于 `min(MSS, 缓存空间/2)`，就会通告窗口为 0，也就阻止了发送方再发送数据。

- 让发送方避免发送小数据

    Nagle 算法，延迟处理，如果两个条件都不满足，发送方就会一直囤积5数据：

    - 条件一：要等到窗口大小 >= `MSS` 或是 数据大小 >= `MSS`；
    - 条件二：收到之前发送数据的 `ack` 回包。

## TCP 拥塞控制

流量控制是防止发送的报文无脑发送填满接收方的缓存，这其中发送方和接收方不知道网络环境是如何变化的，因此当网络出现拥塞的时候，可能会导致包的传输时延增加，丢包等问题，由于重传机制，会进入恶性循环。

拥塞控制最直接的目的就是避免发送方的数据填满整个网络。

拥塞控制算法：

- 慢启动：当发送方每收到一个 ACK 确认报文，就会将拥塞窗口 CWND 的大小 +1，但不是无限增长，有一个阈值记作 ssthreash，小于这个阈值就用慢启动算法，大于等于这个阈值就启动拥塞避免算法；
- 拥塞避免：**每收到一个 ACK 时，cnwd 增加 1/cnwd**，就变成了线性增长；
- 快重传：如果当发送端接收到三个重复的确认 ACK 时，则断定分组丢失，立即重传丢失的报文段，而不必等待重传计时器超时；
- 快速恢复：
    - 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把慢开始门限减半，这是为了预防网络发生拥塞。
    - 由于发送方现在认为网络很可能没有发生拥塞，因此现在不执行慢启动算法，而是把 cwnd 值设置为慢开始门限减半后的值，然后开始执行拥塞避免算法，使拥塞窗口的线性增大。

## TCP 协议保证可靠传输的手段

- 三次握手，建立可信的传输信道

- 校验和，接收端可以检测出来数据是否异常。

- 流量控制

- 拥塞控制

- 停止等待 ARQ 协议

    它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复 ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。

- 重传机制（快速重传、超时重传）

# 网络层

## 为什么 IP 地址和 MAC 地址缺一不可

首先要充分了解网络分层的作用。网络层使用 IP 协议将不同数据链路类型（以太网，3g，LAN）的数据报文统一成相同的形式在网络层中可以互相传播，达到任意具有 IP 地址的主机。但是数据传输总要经过底层，经过线路传输。这时候就是数据链路层起到了作用，不同链路类型所使用的协议方案都不尽相同，但是在链路层不能使用IP地址了，这时候要找到相对应的主机我就需要MAC地址的作用。

若是只使用MAC进行通信，那么一个路由表就要维护差不多2的48次方数据，大约256TB的内存，这样存储和通信效率严重降低。

## ping 的工作原理

ping 是基于 `ICMP` 协议工作，`ICMP` 是互联网控制报文协议，主要功能包括：确认 IP 包是否成功送达目标地址的、未送达的原因等。

在主机 A 执行 ping 命令向主机 B 通信的时候：

主机 A 会构建一个 **ICMP 回送请求消息数据报**，这个数据报最重要的字段是**类型和序号**，序号的作用是为了区分连续 ping 的时候发出的多个数据包。

主机 B 收到数据包：

如果 MAC 地址和本机 MAC 地址匹配则接受，构建一个**ICMP 回送应答消息**数据包。

## traceroute

作用：

1. 设置特殊的 TTL，追踪去往目的地时沿途经过的路由器；

    原理：利用 IP 包的**生存期限** 从 `1` 开始按照顺序递增的同时发送 **UDP 包**，强制接收 **ICMP 超时消息**的一种方法。

2. 故意设置不分片，从而确定路径的 MTU，用于路径 MTU 发现。

    原理：首先在发送端主机发送 `IP` 数据报时，将 `IP` 包首部的**分片禁止标志位设置为 1**。根据这个标志位，途中的路由器不会对大数据包进行分片，而是将包丢弃。随后，通过一个 ICMP 的不可达消息将**数据链路上 MTU 的值**一起给发送主机，不可达消息的类型为「**需要进行分片但设置了不分片位**」。发送主机端每次收到 ICMP 差错报文时就**减少**包的大小，以此来定位一个合适的 `MTU` 值，以便能到达目标主机。

## ARP 协议、RARP 协议

- ARP：

    主要解决 MAC 和 IP 地址之间的问题。确定了 IP 地址之后可以向对应 IP 地址的主机发送数据报，但是在底层数据要通过数据链路进行传输，必须知道每个 IP 地址对应的 MAC 地址才行。

    主机广播发送 ARP 请求，包中包含想要知道的 MAC 地址的主机 IP 地址，收到 IP 地址匹配的主机，将自己的 MAC 地址放入 ARP 响应包中返回给主机。

- RARP：将 ARP 反过来，从 MAC 地址定位到 IP 地址的协议。主要用于无法获取 IP 地址的设备，比如嵌入式设备。

## DHCP 协议

通过 DHCP 协议动态获取 IP 地址。

过程：

- 客户端发起 **DHCP 发送报文**，UDP广播通信，源 IP 地址 0.0.0.0；
- DHCP 服务器收到后，用 **DHCP 提供报文**响应，仍是广播；
- 客户端收到一个或多个 **DHCP 提供报文**后，选择一个服务器，发送 **DHCP 请求报文响应**；
- 服务端用 **DHCP ACK 报文**对 **DHCP 请求报文**进行响应。

## NAT 协议

解决的问题：IPv4 的地址是非常紧缺的，在前面我们也提到可以通过无分类地址来减缓 IPv4 地址耗尽的速度，但是互联网的用户增速是非常惊人的，所以 IPv4 地址依然有被耗尽的危险。

IP 地址 + 端口号一起进行转换，网络地址与端口转换 NAPT

由 NAT 路由器负责

# MySQL

## 数据库事务

### 事务的 ACID 特性

事务就是一组原子性的 SQL 操作，或者说一个独立的工作单元。如果数据库引擎能够成功地对数据库应用该组查询的全部语句，那么就执行该组查询，如果有任何一条语句因为崩溃或者其他原因无法执行，那么所有的语句都不会执行。也就是说事务内的语句，要么全部成功，要么全部失败。

1. 原子性（Atomicity）

    事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。回滚可以用回滚日志（Undo Log）来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。

2. 一致性（Consistency）

    是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。一致性状态下，所有事务对同一个数据的读取结果都是相同的。

3. 隔离性（Isolation）

    数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。

4. 持久性（Durability）

    事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

### 并发一致性问题

MySQL 服务端允许多个客户端连接，意味着 MySQL 会出现同时处理多个事务的情况。

可能出现的问题：

- 脏读

    当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。

- 不可重复读

    在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。

- 幻读

    在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。

严重性：脏读 > 不可重复读 > 幻读

### MySQL 隔离级别

隔离级别：

- 读未提交：指一个事务还没提交时，它做的变更就能被其他事务看到；（都会发生）
- 读已提交：指一个事务提交之后，它做的变更才能被其他事务看到；（脏读不可能发生）
- 可重复读：指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的；（脏读和不可重复读不会发生）
- 可串行化：串行化是4种事务隔离级别中隔离效果最好的，解决了脏读、可重复读、幻读的问题，但是效果最差，它将事务的执行变为顺序执行，与其他三个隔离级别相比，它就相当于单线程，后一个事务的执行必须等待前一个事务结束。（都不会发生）

隔离级别比较：可串行化 > 可重复读 > 读已提交 > 读未提交；

隔离级别对性能的影响比较：可串行化>可重复读>读已提交>读未提交。

隔离级别越高，所需要消耗的 MySQL 性能越大（如事务并发严重性），为了平衡二者，一般建议设置的隔离级别为可重复读，MySQL 默认的隔离级别也是可重复读。

## 数据库锁机制

### 悲观锁和乐观锁

悲观锁：认为当前操作的数据会被外界其他事务所修改，因此在整个数据处理过程中，将数据锁定，屏蔽一切可能违反事务性质的操作。因此每次获取数据的时候都会进行加锁操作，防止外界修改。由于该数据加锁，因此对改数据进行读写操作的其他进程会进入等待状态。**悲观锁的实现需要数据库的锁机制来完成**，只有数据库系统的锁机制才能保证访问的排他性。

乐观锁：乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。

实现方式：用版本号实现。

### 锁的种类

对数据的操作其实只有两种，也就是读和写，而数据库在实现锁时，也会对这两种操作使用不同的锁；InnoDB 实现了标准的行级锁，也就是共享锁（Shared Lock）和互斥锁（Exclusive Lock）

- **共享锁（读锁）**：允许事务对一条行数据进行读取；
- **互斥锁（写锁）**：允许事务对一条行数据进行删除或更新；

### 死锁的产生

InnoDB 中实现的锁是悲观的，那么不同事务之间就可能会互相等待对方释放锁造成死锁，最终导致事务发生错误；想要在 MySQL 中制造死锁的问题其实非常容易：两个会话都持有一个锁，并且尝试获取对方的锁时就会发生死锁。

### 锁的粒度

无论是共享锁还是互斥锁其实都只是对某一个数据行进行加锁

InnoDB 支持多种粒度的锁，也就是**行锁**和**表锁**；为了支持多粒度锁定，InnoDB 存储引擎引入了意向锁（Intention Lock），意向锁就是一种表级锁。

- 行锁

    行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突，提高并发度。其加锁粒度最小，但加锁的开销也最大，还会出现死锁。行级锁分为共享锁和排他锁。

- 表锁

    级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。表级锁分为共享锁和排他锁。开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。

- 意向锁

    为了支持多粒度锁定，InnoDB 存储引擎引入了意向锁（Intention Lock）

    1. **意向共享锁**：事务想要在获得表中某些记录的共享锁，需要在表上先加意向共享锁；
    2. **意向互斥锁**：事务想要在获得表中某些记录的互斥锁，需要在表上先加意向互斥锁；

    意向锁其实不会阻塞全表扫描之外的任何请求，它们的主要目的是为了表示**是否有人请求锁定表中的某一行数据**。

    > 有的人可能会对意向锁的目的并不是完全的理解，我们在这里可以举一个例子：如果没有意向锁，当已经有人使用行锁对表中的某一行进行修改时，如果另外一个请求要对全表进行修改，那么就需要对所有的行是否被锁定进行扫描，在这种情况下，效率是非常低的；不过，在引入意向锁之后，当有人使用行锁对表中的某一行进行修改之前，会先为表添加意向互斥锁（IX），再为行记录添加互斥锁（X），在这时如果有人尝试对全表进行修改就不需要判断表中的每一行数据是否被加锁了，只需要通过等待意向互斥锁被释放就可以了。

### 表级锁和行级锁了解吗？有什么区别？

MyISAM 仅仅支持表级锁(table-level locking)，一锁就锁整张表，这在并发写的情况下性非常差。

InnoDB 不光支持表级锁(table-level locking)，还支持行级锁(row-level locking)，默认为行级锁。行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），所以对于并发写入操作来说， InnoDB 的性能更高。

**表级锁和行级锁对比** ：

- **表级锁：** MySQL 中锁定粒度最大的一种锁，是针对非索引字段加的锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。
- **行级锁：** MySQL 中锁定粒度最小的一种锁，是针对索引字段加的锁，只针对当前操作的行记录进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。

## MySQL 索引

### 索引概念

索引是一种用于快速查询和检索数据的数据结构，常见的索引结构：B 树、B+ 树、Hash。

### InnoDB 使用 B+ 树作为索引的数据结构

B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，而 B 树的所有节点即存放键值也存放数据，因此数据量相同的情况下，相比 B 树，B+ 树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的时候磁盘 I/O次数会更少。(相同的数据量，B+树更矮壮，也是就说，相同的数据量，B+树数据结构，查询磁盘的次数会更少。)

B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；

B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。

### 聚簇索引和非聚簇索引

InnoDB 存储引擎根据索引类型不同，分为聚簇索引和二级索引。

聚簇索引：叶子节点存放的是实际数据，所有完整的用户数据都存放在聚簇索引的叶子节点，找到了索引也就找到了数据。（主键索引就是聚簇索引）

二级索引：叶子节点存放的是主键值，而不是实际数据。所以如果我们使用二级索引列作为查询条件, 如果要查询的数据都在「聚簇索引」的叶子节点里，那么需要检索两颗B+树。

在创建表时，InnoDB 存储引擎默认会创建一个主键索引，也就是聚簇索引，且一张表只允许存在一个聚簇索引，其它索引都属于二级索引。

### 聚簇索引优缺点、适用场景

优点：

1. 数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快
2. 聚簇索引对于主键的排序查找和范围查找速度非常快

缺点：

1. 更新主键的代价很高，维护索引很昂贵，因为将会导致被更新的行移动，导致数据被分到不同的页上。因此，对于InnoDB表，我们一般定义主键为不可更新。

使用聚簇索引的场景：

1. 适合用在排序的场合
2. 取出一定范围数据的时候

### 回表是什么意思，什么是覆盖索引？

在我们使用「二级索引」字段作为条件查询的时候，如果要查询的数据都在「聚簇索引」的叶子节点里，那么需要检索两颗 B+ 树：

- 先在「二级索引」的 B+ 树找到对应的叶子节点，获取主键值；
- 然后用上一步获取的主键值，在「聚簇索引」中的 B+ 树检索到对应的叶子节点，然后获取要查询的数据。上述过程叫做回表

在我们使用「二级索引」字段作为条件查询的时候，如果要查询的数据就在「二级索引」的叶子节点，那么只需要在「二级索引」的 B+ 树找到对应的叶子节点，然后读取要查询的数据就可以了, 不需要再回表, 这个过程叫做覆盖索引。

## InnoDB 存储引擎和 MyISAM 存储引擎的区别

InnoDB:

- 支持事务, 支持4个事务隔离级别
- 行级锁定(更新时锁定当前行)
- 读写阻塞与事务隔离级别有关
- 既能缓存索引又能缓存数据
- 支持外键

MyISAM:

- 不支持事务

- 表级锁定(更新时锁定整个表)

- 读写互相阻塞(写入时阻塞读入, 读时阻塞写入, 但是读不会互相阻塞)

- 只能缓存索引, 不会缓存数据

- 不支持外键

- 读取速度快

## MySQL 语句的执行过程

MySQL 的架构：

首先大方向上要分为两层，server层和存储引擎层。

- server层

    Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

- 存储引擎层

    存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎，现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

**过程：**

1. 连接器

    连接器负责跟客户端建立连接、获取权限、维持和管理连接

2. 查询缓存

    MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。

    如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。

3. 分析器

    分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法规则，只有遵循它的规则，才能获取到在它规则管理内的数据。

4. 优化器

    优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。

5. 执行器

    开始执行语句。开始执行的时候，要先判断一下你对这个表 有没有执行对应操作的权限，如果没有，就会返回没有权限的错误；如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。

    如果表没有索引，会从第一行一行一行地读取，根据where后面的条件是否满足，如果有索引则会根据索引的规则去寻找，然后执行生成结果集。

# Redis

## 关系型数据库和非关系型数据库

**关系型数据库**

采用关系模型来组织数据的数据库。简单说关系模型就是二维表格模型，而关系型数据库就是由二维表及其之间的联系组成的数据结构。

**优点：**

1. 容易理解：二维表结构是非常贴近逻辑世界的一个概念，关系模型相对网状、层次等其他模型来说更容易理解
2. 使用方便：通用的 SQL 语言使得操作关系型数据库非常方便
3. 易于维护：丰富的完整性(实体完整性、参照完整性和用户定义的完整性)大大减低了数据冗余和数据不一致的概率

**缺点：**

1. 高并发读写需求。 网站的用户并发性非常高，往往达到每秒上万次读写请求，对于传统关系型数据库来说，硬盘 I/O 是一个很大的瓶颈
2. 海量数据的高效率读写。 网站每天产生的数据量是巨大的，对于关系型数据库来说，在一张包含海量数据的表中查询和修改，效率是非常低的
3. 高扩展性和可用性。在基于 web 的结构当中，数据库是最难进行横向扩展的，当一个应用系统的用户量和访问量与日俱增的时候，数据库却没有办法像 web server 和 app server 那样简单的通过添加更多的硬件和服务节点来扩展性能和负载能力。对于很多需要提供24小时不间断服务的网站来说，对数据库系统进行升级和扩展是非常痛苦的事情，往往需要停机维护和数据迁移。

**非关系型数据库**

NoSQL 非关系型数据库，主要指那些非关系型的、分布式的，且一般不保证 ACID 的数据存储系统。NoSQL提出了另一种理念，以键值来存储，且结构不稳定，每一个元组都可以有不一样的字段，这种就不会局限于固定的结构，可以减少一些时间和空间的开销。使用这种方式，为了获取用户的不同信息，不需要像关系型数据库中，需要进行多表查询。仅仅需要根据key来取出对应的value值即可。

**优点：**

1. 格式灵活：存储数据的格式可以是key,value形式、文档形式、图片形式等等，文档形式、图片形式等等，使用灵活，应用场景广泛，而关系型数据库则只支持基础类型。
2. 速度快：nosql可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘；
3. 高扩展性。
4. 成本低：nosql数据库部署简单，基本都是开源软件。

**缺点：**

1. 不提供sql支持，学习和使用成本较高；
2. 无事务处理；
3. 数据结构相对复杂，复杂查询方面稍欠。

## 持久化机制

Redis 是一个支持持久化的内存数据库，通过持久化机制把内存中的数据同步到硬盘文件来保证数据持久化。当 Redis 重启后通过把硬盘文件重新加载到内存，就能达到恢复数据的目的。

很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机 器、机器故障之后回复数据），或者是为了防止系统故障而将数据备份到一个远程位置。

两种机制：

- 快照（RDB）持久化
- AOF 持久化

**RDB 持久化**

Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行 备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。

**AOF 持久化**

与快照持久化相比，AOF **持久化的实时性更好**，开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。

两个模式的选择：

1. 如果主要充当缓存功能，或者可以承受数分钟数据的丢失，通常生产环境一般只需启用 RDB 可，此也是默认值。
2. 如果数据需要持久保存，一点不能丢失，可以选择同时开启 RDB 和 AOF，一般不建议只开启 AOF

