# web轻量级服务器

## 简要概述

该服务器是我看完游双老师《Linux高性能服务器编程》这本书和github一些优秀的开源项目的参考，根据自己的理解实现的一个轻量级的服务器。

这个项目主要根据书中的知识写了一个简易的服务器，为了验证这个服务器的能力，最直观的办法就是通过网页来和服务器端进行交互。服务器对浏览器的连接进行解析处理，处理完成后给客户返回一个响应，比如一张图片一行字等。服务器后端的处理使用的是socket通信，利用IO多路复用来处理并发请求。使用线程池来解析请求。事件处理模型用的是Reactor实现的， 并发模式用的是半同步/半反应堆模式，主要的步骤是主线程也作为一个异步线程，使用epoll作为IO多路复用实现方式，只负责监听文件描述符上是否有可读事情发生，如果有的话主线程就将监听socket然后往epoll内核事件表中注册该socket上的读写事件。如果连接socket上有读写事件发生，即客户端有数据过来或者要将数据发送到客户端，就将请求对象插入请求队列。所有工作线程通过竞争的方式来获得请求对象的处理权，只有空闲的工作线程才有机会得到任务。

我用了一个主线程和默认四个工作线程，主线程将任务添加到线程池，任务即就绪待处理的文件描述符,epoll使用EPOLLONESHOT保证一个socket连接在任意时刻都只被一个线程处理。同时epoll的触发模式选择了ET模式，ET模式要高效很多，不会被同一事件触发多次，每次读都必须循环读取直到EAGIN错误，确保处理完。

> **项目架构:**
>
> - 主线程：
>   1. 在主线程中，epoll监听套接字，处理新客户的连接请求，或者是已连接客户的写请求
>   2. 将写请求封装成一个request_data对象，这个对象包括文件描述符，发送的报文，数据的处理函数等
>   3. 设置request_data中的timer为NULL，表示处理完一个request_data就delete，所以默认是短连接。如果报文解析到长链接，则会在后面补上timer时间。然后将request_data对象放在线程池的任务队列中等待工作线程的处理
>   4. 主线程还有一个while循环，利用最小堆管理定时器节点，删除超时事件。
> - 工作线程：
>   1. 工作变量使用封装好的同步机制类从任务队列中取出任务，利用request_data自己的处理函数分析http报文，发送http响应
>   2. 如果分析到报文里面有keep_alive选项，则不会销毁request_data对象，而是清空对象中的消息保留下来。
>   3. keep-alive长连接不是永久保留的，而是设置了一个定时器（也就是keep-alive中的timer成员）超时，超出时间以后，就把他关闭掉，这里超时时间设定为500ms。然后加入到最小堆中。
>   4. 最后由于一开始fd是EPOLLNOESHOT模式，还需要再epoll ctl设置一下fd的状态，使得他可以再次被监听。



## 特点

- 使用epollIO复用 + 非阻塞IO + 边缘触发(ET) 实现高并发处理请求，事件处理模式使用的是Reactor

- 线程池提高并发，降低频繁创建线程的开销

  线程池的实现模型就是半同步/半反应堆的。有三个类，任务类，任务队列类，线程池类。

- RAII手法封装线程同步机制

- epoll使用EPOLLONESHOT保证一个socket连接在任意时刻都只被一个线程处理

- 状态机解析HTTP请求，目前支持 HTTP GET、POST

- 添加定时器处理非活动连接，使用最小堆结构管理定时器

## 面试问题

[参考](https://www.nowcoder.com/discuss/934904)

### HTTP报文解析

- http报文格式

  HTTP报文分为请求报文和响应报文两种，每种报文必须按照特有格式生成，才能被浏览器端识别。

  请求报文由**请求行（request line）、请求头部（header）、空行和请求数据**四个部分组成。

  请求报文分为两种，POST和GET。

  > POST和GET的区别？
  >
  > 1. ET在浏览器回退时是无害的，而POST会再次提交请求。
  > 2. GET产生的URL地址可以被Bookmark，而POST不可以。
  > 3. GET请求会被浏览器主动cache，而POST不会，除非手动设置。
  > 4. GET请求只能进行url编码，而POST支持多种编码方式。
  > 5. GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
  > 6. GET请求在URL中传送的参数是有长度限制的，而POST没有。
  > 7. 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。
  > 8. GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。
  > 9. GET参数通过URL传递，POST放在Request body中

  HTTP响应也由四个部分组成，分别是：**状态行、消息报头、空行和响应正文。**

- http状态码

  HTTP有5种类型的状态码，具体的：

  - 1xx：指示信息--表示请求已接收，继续处理。
  - 2xx：成功--表示请求正常处理完毕。
    - 200 OK：客户端请求被正常处理。
    - 206 Partial content：客户端进行了范围请求。
  - 3xx：重定向--要完成请求必须进行更进一步的操作。
    - 301 Moved Permanently：永久重定向，该资源已被永久移动到新位置，将来任何对该资源的访问都要使用本响应返回的若干个URI之一。
    - 302 Found：临时重定向，请求的资源现在临时从不同的URI中获得。
  - 4xx：客户端错误--请求有语法错误，服务器无法处理请求。
    - 400 Bad Request：请求报文存在语法错误。
    - 403 Forbidden：请求被服务器拒绝。
    - 404 Not Found：请求不存在，服务器上找不到请求的资源。
  - 5xx：服务器端错误--服务器处理请求出错。
    - 500 Internal Server Error：服务器在执行请求时出现错误。

- http报文处理流程

  - 浏览器端发出http连接请求，主线程创建http对象接收请求并将所有数据读入对应buffer，将该对象插入任务队列，工作线程从任务队列中取出一个任务进行处理。
  - 工作线程取出任务后，调用process_read函数，通过主、从状态机对请求报文进行解析。
  - 解析完之后，跳转do_request函数生成响应报文，通过process_write写入buffer，返回给浏览器端。

- http报文解析流程

  - 各个工作线程通过process函数对任务进行处理，调用process_read函数和process_write函数分别完成报文解析和报文响应两个任务。在解析的过程中我们是用主从状态机，根据特定的状态执行对应的逻辑代码。

  - 对于请求报文来说。从宏观逻辑上将，从状态机负责读取报文的一行，主状态机负责对改行数据进行解析，主状态机内部调用从状态机，从状态机驱动主状态机前进读取下面的数据。

    从状态机逻辑是这样的。要知道在HTTP报文中，每一行的数据由\r\n作为结束字符，空行则是仅仅是字符\r\n。因此，可以通过查找\r\n将报文拆解成单独的行进行解析，项目中便是利用了这一点。从浏览器发过来的数据存放在缓冲区buffer中，从状态机读取buffer中的数据，将每行数据末尾的\r\n置为\0\0，并更新从状态机在buffer中读取的位置m_checked_idx，以此来驱动主状态机解析。

    主状态机逻辑如下。主状态机有三个函数分别是

    1. parse_request_line函数解析请求行——对应主状态机状态CHECK_STATE_REQUESTLINE
    2. parse_headers函数解析请求头部信息——对应主状态机状态CHECK_STATE_HEADER
    3. parse_content函数解析消息体——对应主状态机状态CHECK_STATE_CONTENT

    主状态机的初始状态为CHECK_STATE_REQUESTLINE，调用parse_request_line函数解析请求行，获得请求方法、目标URL及HTTP版本号，解析完成后主状态机的状态变为CHECK_STATE_HEADER。接着调用parse_headers函数解析请求头部信息，判断是空行还是请求头，若是空行，进而判断content-length是否为0，如果不是0，表明是POST请求，则状态转移到CHECK_STATE_CONTENT，否则说明是GET请求，则报文解析结束。CHECK_STATE_CONTENT仅用于解析POST请求，调用parse_content函数解析消息体。

  - 生成响应报文和发送数据。服务器子线程调用`process_write`完成响应报文，随后注册`epollout`事件。服务器主线程检测写事件，并调用`http_conn::write`函数将响应报文发送给浏览器端。

- 为什么用有限状态机

  ①传统应用程序的控制流程基本是按顺序执行的：遵循事先设定的逻辑，从头到尾地执行。如果我们想实现不同状态对应不同的逻辑，就需要跳转代码，可能会造成逻辑混乱不清晰。每个状态都有一系列的转移，每个转移与输入和另一状态相关。当输入进来，如果它与当前状态的某个转移相匹配，机器转换为所指的状态，然后执行相应的代码。

  ②http引用层协议个字段都由一些特殊的字符分割，很容易可以联想到在编译原理中构造词法分析器时使用的有限状态自动机，将对于不同字段的识别过程设置为不同的状态，每当识别到分割字符时，就改变当前状态。这样将整个报文首部逐字符扫描一遍后，就可以解析出每个字段了。

- https协议为什么安全？

  > https=http+ssl但是现在ssl都被tsl所取代

  首先说明为什么http协议不安全？**首先要知道一个安全的机制应该满足三个特性：机密性，完整性，不可否认性。**http协议通信使用明文进行通信，且没有任何其他保护措施，我们依次来看一下不安全特性。首先是机密性，由于使用明文进行通信，导致信息会被窃听泄露；然后是完整性，一段裸奔的明文在网络上传递，会被轻而易举的篡改；最后是不可否认性，由于http的请求和响应不会对通信方的身份进行确认，导致很容会被欺骗，而且用户无法察觉

  但是https使得上述三个特性都满足。

  HTTPS并非是应用层的一种新协议。只是HTTP通信接口部分用SSL（Secure Socket Layer）和TLS（Transport Layer Security）协议代替而已。

  通常，HTTP直接和TCP通信。当使用SSL时，则演变成先和SSL通信，再由SSL和TCP通信了。简言之，**所谓HTTPS，其实就是身披SSL协议这层外壳的HTTP（SSL协议位于TCP和HTTP协议之间）**。SSL主要包括几大块：

  1. 解决机密性。对请求和应答消息进行加密。公钥加密效率比较低，对称加密效率较高。因此对于密钥协商这块，使用公钥两方协商密钥，然后用密钥执行对称加密对消息加密
  2. 完整性。依靠单向散列函数实现，比如MD5或者SHA1
  3. 不可否认性。依靠数字签名来实现。

- https的ssl连接过程

  ![img](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203071410891.png)

  ![img](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203071411049.png)

- 怎么分清楚客户端的两次不同的请求？

  

### **线程池相关**

- 手写线程池

- 线程的同步机制？

  ①POSIX信号量

  ②互斥量

  ③条件变量

- 为什么创建线程的开销大？

  操作系统需要发生系统调用，陷入内核，调用内核API创建线程，为线程分配资源等。如果在一个IO频繁的服务器上每次来创建线程的话，效率会很慢。

- 为什么要是用线程池？

  ①降低资源消耗。通过重复利用已创建的线程，降低线程创建和销毁造成的消耗。

  ②提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。

  ③增加线程的可管理型。线程是稀缺资源，使用线程池可以进行统一分配，调优和监控。

- 线程池中的工作线程是一直等待吗？

  是的，等待阻塞队列出现新任务然后唤醒。

- 你的线程池工作线程处理完一个任务后的状态是什么？

  分情况讨论。先判断任务队列是否为空，为空的话就判断是否有需要销毁的线程，有的话销毁一部分线程，没有的话存活的线程阻塞等待。如果不为空就继续从任务队列中取任务（和其他线程一起竞争），然后处理

- 线程池中核心线程数量大小怎么设置？

  要分CPU密集型还是IO密集型。比如解压，加密解密这种耗费CPU资源的任务，可以使用数量较少的线程池，因为切换的不频繁，线程多了造成频繁的切换可能会使得效率较低

  如果是IO密集型，比如文件读写，网络通信等任务，不会很消耗CPU资源，使用的线程数一般为CPU核心数的两倍。IO密集型任务CPU使用率并不高，因此可以让CPU在等待IO的时候有其他线程去处理别的任务，充分利用CPU时间。线程的平均工作时间所占比例越高，就需要越少的线程；线程的平均等待时间所占比例越高，就需要越多的线程；

- 线程池为什么要用阻塞队列？

  阻塞队列可以保证当没有任务的时候线程被阻塞，释放CPU资源，使得线程不用一直轮询进而耗费CPU资源

- 线程池中的线程复用？

  在线程池中，同一个线程可以从阻塞队列中不断获取新任务来执行，因为每个线程都进行这循环，不断地从任务队列中提取任务来执行

- 线程池的核心参数？

  存活线程数，忙线程数，最大和最小线程数，是否销毁表示，需要退出的线程数

- 你是如何判断线程需要销毁的？

  当忙线程*2 <  存活线程数，就销毁几个线程。

  当任务队列数量 > 存活线程数时，就创建几个线程用。

- 线程池类中的线程处理函数为什么要是static的？

  因为类中，类函数的参数列表一般都会隐藏一个this指针，在你写的时候是默认不显示的，但当代码编译之后这个this指针的形参就会出来、

  而`pthread_create()`函数中要求的回调函数的格式是`void *ThreadFunc(void *args);`，只有一个参数。

  所以如果线程处理函数不加static的话，形参数目不匹配，就会编译不通过。

  类函数加上static关键字后就表明类的静态函数不属于任何一个对象，而是这个类本身所有。

  其次，可以想一想，如果static不用加，那么这个对象生命周期结束了，这个线程池就不能用了吗？显然是不合逻辑的，因此两个原因都表明了线程处理函数必须是类的静态函数才行。

- 如果同时1000个客户端进行访问请求，线程数不多，怎么能及时响应处理每一个呢？

  这个问题也相当于问你如何处理高并发？

  首先要知道不是每一个用户对应一个线程，这样的话像双十一这种高并发的场景下早就崩了。其次线程处理函数也就是**子线程内部都有一个while循环，让线程池中的线程永远不会终止，处理完当前任务就去处理下一个，当任务队列为空的时候就阻塞**，就是我们常说的007模式。一般来说应对大量并发的情况下最终还是要靠硬件层面来解决问题，也就是增大线程池容量或者考虑集群分布式的做法。

- 如果一个客户请求需要占用线程很久的时间，会不会影响接下来的客户请求呢，有什么好的策略呢?

  这个当然会，因为线程数就这么多，你一直占着一个线程势必会影响到服务器对外的整体响应速度。

  解决办法：可以给每一个任务设置一个时间阈值，当请求过长时从新入队列或者就断开。



### 模型框架

- **半同步半反应堆有什么问题或者缺点吗？**

  1. 由于主线程和工作线程共享队列，因此添加任务和取任务都要加锁，会浪费CPU时间
  2. 每个工作线程同一时间只能处理一个客户请求。当客户较多而工作线程比较少的时候，任务队列中就会堆积很多任务对象，导致客户端的响应速度变慢

  解决办法：半同步/半反应堆2.0模式。主线程主管监听，连接操作由工作线程管理。当有新连接来的时候，主线程接受后返回新连接的socket给某个工作线程，以后该socket上的任何IO操作都由被选中的工作线程处理，直到关闭。主线程通过管道向工作线程派发socket。每个工作线程都有自己的内核事件表，都维持着自己的事件循环，各自监听不同的时间。所以每个工作线程都工作在异步模式。

- **说一下reactor和practor**

  具体看《Linux服务器》章节有写。

- **为什么用epoll？还有没有其他的IO复用方式？**

  就是问epoll和select之间的优劣势。这个我也放到《Linux服务器》章节了。

- **五大IO模型**

  **IO两个阶段：首先是等待数据就绪即等待网络数据被copy到内核缓冲区(IO事件)，第二阶段是将数据从内核缓冲区copy到用户缓冲区(IO读写操作)。**

  - 阻塞IO
  - 非阻塞IO
  - IO多路复用
  - 信号驱动IO
  - 异步IO

- **阻塞和非阻塞，同步与异步**

  **阻塞和非阻塞的区别**在于内核数据还没准备好时，用户进程在**一阶段数据准备时**是否会阻塞；**同步与异步的区别**在于当数据从内核`copy`到用户空间时，用户进程是否会阻参与**第二阶段的数据读写**，是由用程序完成还是由内核完成。

  阻塞IO、IO复用、信号驱动IO都是同步IO模型，因为这三种模型中IO的读写操作都是发生在IO事件之后，由应用程序完成的，而不是内核。异步IO是内核对IO执行操作，完成之后内核再通知应用程序，所以异步IO的读写总是立即返回，不论IO是否阻塞，因为真正的读写操作给了内核去完成。

  同步IO通知的是IO就绪事件，异步IO通知的是IO完成事件（从内核拷贝到用户完成）

- **两种高效的并发模式**

  


### 定时器相关

- **定时器怎么设计的？**

  定时器处理非活动连接模块，主要分为两部分，其一为定时方法与信号通知流程，其二为定时器及其容器设计与定时任务的处理。

  - 定时方法与信号流程通知

    信号流程通知：服务器主线程为每一个连接创建一个定时器，并对每个连接进行定时。利用时间堆将所有定时器集合起来起来，若主循环接收到定时通知，则在时间堆中依次执行定时任务。使用`alarm`函数周期性地触发`SIGALRM`信号，信号处理函数利用管道通知主循环，主循环接收到该信号后将设置一个标志位，比如timeout=true，然后就对时间堆上排第一的定时器进行处理，若该段时间内没有交换数据，则将该连接关闭，释放所占用的资源。

    处理定时任务函数：SIGALRM信号每次被alarm函数触发，主循环中调用超时时间拍第一的定时器的tick函数，处理容器中到期的定时器。

    定时器的使用：

    1. 浏览器与服务器连接时，创建该连接对应的定时器，并将该定时器添加到最小堆中
    2. 处理异常事件时，执行定时事件，服务器关闭连接，从堆上移除对应定时器
    3. 处理定时信号时，将定时标志设置为true，因为处理定时器为非必须事件，收到信号并不是立马处理，可以完成读写事件后，再进行处理
    4. 处理读事件时，若某连接上发生读事件，调整该连接对应的定时器，否则，执行定时事件
    5. 处理写事件时，若服务器通过某连接给浏览器发送数据，调整该连接对应的定时器，否则，执行定时事件

  - 定时器容器设计和定时任务处理

    最小堆定时器：将定时器中超时时间最小的超时值作为心搏间隔。一旦心搏函数tick被调用，超时时间最小的定时器必然到期，就可以在tick函数中处理该定时器。接着从剩余定时器中找出一个超时时间最小的，并将这个最小时间设定为下一次心搏函数，这样可以实现较为精确的定时。对于时间堆而言添加一个定时器的复杂度是O(lgn)，删除定时器的时间复杂度是O(1)，执行一个定时器的时间复杂度是O(1)

    定时器类：将连接的资源、定时事件(即回调函数)和超时时间封装。这里面定时事件就是从内核事件表中删除事件，关闭文件描述符，释放链接资源。

- **为什么要有定时器？**

  如果一个客户端与服务器长时间连接，并且不进行数据的交互，这个连接就没有存在的意义还占据了服务器的资源。在这种情况下，服务器就需要一种手段检测无意义的连接，并对这些连接进行处理。除了处理非活跃的连接之外，服务器还有一些定时事件，比如关闭文件描述符等。为实现这些功能，服务器就需要为各事件分配一个定时器。节省系统资源。
  
- **定时器都有哪些实现？**

  升序链表：添加定时器任务是O(n)，删除定时器是O(1)，执行定时器复杂度是O(1)

  定时轮：一个轮子n个槽，每个槽是个定时器的链表，哈希表的思想将定时器散列到不同的链表上。那么添加定时器的时间复杂度是O(1)，删除定时器是O(1)，执行一个定时器的时间复杂度是O(n)

  最小堆

- **连接资源包括什么？**

  连接资源包括客户端套接字地址、文件描述符，读缓存和定时器。

- **超时时间**

  我使用绝对时间作为超时值。超时时间=浏览器和服务器连接时刻 + 固定时间(TIMESLOT)，



### 实现细节相关

- **为什么信号处理的管道的写端要设置为非阻塞？**

  send是将信息发送给套接字缓冲区，如果缓冲区满了，则会阻塞，这时候会进一步增加信号处理函数的执行时间，为此，将其修改为非阻塞。

- **c++设计模式用到过那些？？**

  单例模式（具体看设计模式中单例模式的概念和问题），工厂模式

- **epoll的EPOLLONESHOT作用是什么？**

  使用ET模式，一个socket上的某个事件还是可能被触发多次。比如一个线程在读取完一个socket数据后去处理，但是数据的处理过程中socket上又有新数据可读，这样就会导致另外一个线程过来处理这些数据，就会出现两个线程同时操作一个socket的局面。

  但是我们希望socket连接在任意时刻只被一个线程处理，可以引用其实现。

  当注册了EPOLLONESHOT事件一旦被某个线程处理，该线程必须重置这个socket上的EPOLLONESHOT事件，以确保下一次socket可用。
  
- **epoll相关代码**

  项目中epoll相关代码部分包括非阻塞模式、内核事件表注册事件、删除事件、重置EPOLLONESHOT事件四种。

### 服务器相关

- **如果服务器连接了许多无效连接，如何处理？**

  **也可以问：tcp连接的异常关闭导致服务端留下了大量ESTABLISHED状态的连接**

  无效的连接有几种情况：

  1. client异常“关闭”了connection：这里的“异常”有多种可能性，client机器奔溃了、client端程序异常退出，这两种情况都没有调用close，发送FIN。
  2. 也有可能server端机器的中断机制异常，导致对应FIN包的处理出现问题，没有顺利处理TCP的四次挥手接下来流程。

  思路就是我们只需要对这些连接实现一次发包处理，就能解决这个问题，正好tcp中有一个KeepAlive机制

  KeepAlive默认不是开启的，如果想使用KeepAlive，需要在你的应用中设置SO_KEEPALIVE才可以生效。

- **连接中服务器挂掉了或者死机了，会怎样**

  超时重传机制应该会是。tcp模块为每个报文段都维持了一个重传定时器，如果超时时间未收到接收方的答复，tcp将重传报文段并重置定时器。linux中时五次重传，每次重传时间段增加一倍。如果五次重传都失败了，则底层IP和ARP开始接管，知道放弃连接。

### 印象深刻的难题？如何解决？

- 关于服务器端setsocketopt没有设置SO_REUSEADDR的问题

  **找问题**

  我在开发一个socket服务器程序并反复调试的时候，发现了一个让人无比心烦的情况：每次kill掉该服务器进程并重新启动的时候，都会出现bind错误：**error:98，Address already in use。**然而再kill掉该进程，再次重新启动的时候，就bind成功了。真让人摸不着头脑。难道一定要尝试两次才显得真诚？这不科学！

  我的第一反应是kill进程的时候，并没有完全释放掉socket资源，倒致第二次启动的时候，bind失败。那么第三次怎么又成功了呢？

  查资料：有人说是TIME_WAIT在捣鬼。回想一下，Linux下的TIME_WAIT大概是2分钟，这样也合情合理。那么没有释放掉的资源是什么呢，是端口吗？机智的我立刻决定做实验找出答案。启动服务器程序，在与客户建立连接之后，kill掉服务器。飞快地在terminal里输入命令：netstat -an|grep 9877。这里9877是我服务器打算绑定的端口。果然：

  　　![img](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202204061026001.jpeg)

  结果显示9877端口正在被使用，并处于TCP中的TIME_WAIT状态。再过两分钟，我再执行命令netstat -an|grep 9877，世界清静了，什么都没有。终于找到了答案：果然是TIME_WAIT在捣鬼。

  **解决问题**

  　如何才能结束掉这个TIME_WAIT状态呢？否则每次调试之后，都要巴巴地等上两分钟，再进行下次调试或者kill两次。UNP中第7章就是讲socket选项的。没有找到能关闭掉TIME_WAIT的选项。但是找到了SO_REUSEADDR选项。关于此选项书上说了：“所有TCP服务器都应该指定本套接字选项，以允许服务器在这种情形下被重新启动。”

  　　![img](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202204061028148.jpeg)

     上面两行代码，把此套接字listenFd设置为允许地址重用（on=1,如果on=0就是不允许重用了）。这样每次bind的时候，如果此端口正在使用的话，bind就会把端口“抢”过来。就不会报错了。完美解决问题。





+++

# 缔安科技实习项目

## 公司介绍

上海缔安科技股份有限公司成立于2007年，SD-WAN安全云网络运营服务提供商。主要是给企业提供安全组网服务，

> SD-WAN本质上就是用软件实现传统WAN硬件设备的功能。WAN就是广域网，在公司里面大多数WAN路由器在TCP层分离流量，因此无法将业务关键流量与不太紧急的流量分开，而且许多应用程序和进程都需要无抖动的网络连接。同时在传统的WAN部署中，每个网段都需要专用的物理硬件，这通常非常昂贵。即使很小的扩容、升级或重新配置也可能带来巨额的费用。
>
> SD-WAN允许通过中央管理控制台对分支网络进行集中管理，从而无需对WAN路由器进行物理访问，也无需现场IT人员进行手动配置。它还提供了对网络的更多可见性，并为IT人员和中层管理人员提供了通用的网络视图。由于网络同时使用私有和公共传输介质来路由流量，因此这也为传输介质类型和传输供应商选择提供了更多选择。

所以说我这个岗位感觉更像是网络工程师，不像是c++工程师。

## 业务背景介绍

我的业务主要是对于公司产品的缝缝补补和性能改进这方面的工作，主要是对于vpp的一些开发。

vpp是思科研发的一个框架，提供交换机路由器的功能。

## 第一个任务

**负责收取设备网卡的收发流量，使用redis的缓存功能存储。**

该软件有两个层，外层就是提供给用户进行配置的，底层就是用的思科研发的vpp架构处理数据包

对于通过这些设备的流量来说，其实设备可以理解为一台计算机，流量通过或者从一个网卡发出，就叫做rx和tx

对于这些流量数据存储从map中取出放到redis中，第一个工作就很简单。

问：为什么之前用map存储rx和tx流量，现在改成redis呢？

答：首先map实现的是本地缓存，主要是快速和轻量，但是不能持久化，程序一重启就没了。redis用内存作为缓存，每秒百万的并发量其实很大的。其次就是如果缓存东西太多容易挂掉，特别是随着程序的运行，流量数据会变得很多，放到map里面容易挂掉。

## 第二个任务

这个项目的大致目的是，添加一个白名单功能，在白名单中的网站的流量都可以放行

业务逻辑是这样的：为了实现对网站细粒度的访问，定义了三种级别，举个例子比如休闲娱乐—视频网站—腾讯视频这种，这样我们可以实现对某一个或者某一类网站访问的控制权。白名单的意思就是说我定义了某一类网站不能访问，但我需要某一个网站的访问权，相当于开个后台。

逻辑是这样的，每一级分类对应一个序列号，三级分类就是将每级分类ID级联起来这样的话每个网站就有一个ID表示。

## 第三个任务shell转c

这个是我写的最久的。



# GDB调试

## 普通调试

- step和next的区别？

		next会直接执行到下一句 ,step会进入函数体内部执行

- list

		查看源码

- set

  设置变量值

- backtrace 

  查看函数调用的栈帧关系

- framework

  切换函数栈帧

- info

  查看函数内部局部变量

## 多线程调试

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203151449773.png" alt="这里写图片描述" style="zoom: 80%;float:left" />

- info threads

  查看所有线程，默认分支是主线程

- thread id

  切换线程

- bt

  查看每个线程的栈帧然后设置断点

- thread apply （n或all） 命令

  使用thread apply来让一个或是多个线程执行指定的命令。例如让所有的线程打印调用栈信息。

- set scheduler-locking on

  锁定只有当前的线程能够执行

## 遇到过程序崩溃的情况吗？怎么调试？gdb咋用的



<hr/>

# RPC（远程过程调用）

> **演化过程**
>
> 我们在做一个访问量不大的项目的时候,一台服务器部署上一个应用+数据库也就够了.
>
> 那么访问量稍微大一点之后呢,为了解决用户反馈的卡,反应慢的情况,我们就上集群.架设nginx,部署多个服务,由nginx负责把请求转发到其他服务上,这样就解决了用户说的卡慢问题.
>
> 过了一段时间之后呢,我们发现数据库已经扛不住了,应用服务完好,数据库有时候宕机. 那这个时候呢,我们就上数据库读写分离,再架设几台数据库服务器,做主从,做分库分表. 然后数据库也不宕机了,服务又恢复了流畅.
>
> 又过了一段时间,公司事业增增日上,服务访问量越来越高,且大部分都是查询, 吸取之前宕机且为了办证数据库的健壮性,我们这个时候又加上了缓存, 把用户高频次访问的数据放到缓存里.
>
> 后来,项目功能越来越多,整个项目也愈发庞大,修改一个类就需要全盘上传,切换nginx重启,这样的发布流程越来越长,越来越繁杂.然后我们开始把模块拆分,用户信息分个项目,订单系统分一个项目.这样就达到了,用户模块代码修改的时候,只需要更新用户信息服务就好了.但是还是需要切换顶层的nginx.把要重启的服务的流量切到可用服务上. 这个时候我们就想到了RPC
>
> 那么RPC解决了什么呢? 所有的服务在启动的时候注册到一个注册机里面,然后顶层处理在接收到nginx的请求时,去注册机找一个可用的服务,并调用接口. 这样子呢,在不加新功能的时候,顶层处理服务我们就不需要动了? 那修改了用户信息项目的时候,我们只需要一个个更新用户信息项目的服务群就好了?



## 概念

**RPC是指远程过程调用**，也就是说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。

为什么RPC呢？就是无法在一个进程内，甚至一个计算机内通过本地调用的方式完成的需求，比如比如不同的系统间的通讯，甚至不同的组织间的通讯。由于计算能力需要横向扩展，需要在多台机器组成的集群上部署应用



## PRC所具有的的问题

说问题之前我们先说一下本地函数调用，如下有一段代码：

```c++
int Multiply(int l, int r) {
   int y = l * r;
   return y;
}
int lvalue = 10;
int rvalue = 20;
int l_times_r = Multiply(lvalue, rvalue);
```

其函数调用操作如下：

1. 将 lvalue 和 rvalue 的值压栈
2. 进入Multiply函数，取出栈中的值10 和 20，将其赋予 l 和 r
3. 执行第2行代码，计算 l * r ，并将结果存在 y
4. 将 y 的值压栈，然后从Multiply返回
5. 第8行，从栈中取出返回值 200 ，并赋值给 l_times_r

> 事实上编译器经常会做优化，对于参数和返回值少的情况会直接将其存放在寄存器，而不需要压栈弹栈的过程，甚至都不需要调用call，而直接做[inline操作](https://www.zhihu.com/search?q=inline操作&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A221638079})。仅就原理来说，这5步是没有问题的。）

在远程调用时，我们需要执行的函数体是在远程的机器上的，也就是说，Multiply是在另一个进程中执行的。这就带来了几个新问题：

**Call ID映射**

我们怎么告诉远程机器我们要调用Multiply，而不是Add或者FooBar呢？在本地调用中，函数体是直接通过函数指针来指定的，我们调用Multiply，编译器就自动帮我们调用它相应的函数指针。但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。所以，在RPC中，所有的函数都必须有自己的一个ID。这个ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个ID。然后我们还需要在客户端和服务端分别维护一个 {Function，Call ID} 的对应表(hash map)。两者的表不一定需要完全相同，但相同的函数对应的Call ID必须相同。当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。

**序列化和反序列化**

客户端怎么把参数值传给远程的函数呢？在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。甚至有时候客户端和服务端使用的都不是同一种语言（比如服务端用C++，客户端用Java或者Python）。当A服务器上的应用发起远程过程调用时，方法的参数需要通过底层的网络协议如TCP传递到B服务器，由于网络协议是基于二进制的，内存中的参数的值要序列化成二进制的形式，也就是序列化（Serialize）或编组（marshal），通过寻址和传输将序列化的二进制发送给B服务器。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。

**网络传输**

远程调用往往用在网络上，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。



## RPC的stub结构

<img src="https://s2.loli.net/2022/06/29/ZLuHjWf2YdG9aOq.png" alt="img" style="float: left;" />

RPC 服务方通过 `RpcServer` 去导出（export）远程接口方法，而客户方通过 `RpcClient` 去引入（import）远程接口方法。客户方像调用本地方法一样去调用远程接口方法，RPC 框架提供接口的代理实现，实际的调用将委托给代理`RpcProxy` 。代理封装调用信息并将调用转交给`RpcInvoker` 去实际执行。在客户端的`RpcInvoker` 通过连接器`RpcConnector` 去维持与服务端的通道`RpcChannel`，并使用`RpcProtocol` 执行协议编码（encode）并将编码后的请求消息通过通道发送给服务方。RPC 服务端接收器 `RpcAcceptor` 接收客户端的调用请求，同样使用`RpcProtocol` 执行协议解码（decode）。解码后的调用信息传递给`RpcProcessor` 去控制处理调用过程，最后再委托调用给`RpcInvoker` 去实际执行并返回调用结果。

> 每个组件的职责：
>
> 1. RpcServer   负责导出（export）远程接口 
>
> 2. RpcClient   负责导入（import）远程接口的代理实现 
>
> 3. RpcProxy   远程接口的代理实现 
>
> 4. RpcInvoker
>
>    客户方实现：负责编码调用信息和发送调用请求到服务方并等待调用结果返回 
>
>    服务方实现：负责调用服务端接口的具体实现并返回调用结果 RpcProtocol   负责协议编/解码 
>
> 5. RpcConnector   负责维持客户方和服务方的连接通道和发送数据到服务方 
>
> 6. RpcAcceptor   负责接收客户方请求并返回请求结果 
>
> 7. RpcProcessor   负责在服务方控制调用过程，包括管理调用线程池、超时时间等 
>
> 8. RpcChannel   数据传输通道



一个完整的使用场景下的RPC结构

<img src="https://s2.loli.net/2022/06/29/XdizqbJsT4WkjN1.jpg" alt="img" style="zoom:80%;float:left" />

所以自己实现的最简单的RPC功能可以包含一下三个：

1. 服务寻址(又叫做Call ID映射)
2. 数据流的序列化和反序列化
3. 网络传输